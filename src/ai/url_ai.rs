use anyhow::Result;
use serde_json::{json, Value};
use tracing::{info, debug, warn};
use std::collections::HashMap;
use url::Url;
use serde::{Deserialize, Serialize};
use async_openai::{Client, types::{CreateChatCompletionRequestArgs, ChatCompletionRequestMessage, Role}};

use super::ai_service::{AIService, AIRequest};
use super::prompt_templates::UrlPrompts;

/// AIå¢å¼ºçš„URLåˆ†æå™¨
pub struct UrlAI {
    ai_service: AIService,
    prompts: UrlPrompts,
    /// ç¼“å­˜åˆ†æç»“æœ
    analysis_cache: std::sync::Arc<tokio::sync::RwLock<HashMap<String, UrlAnalysisResult>>>,
}

/// URLåˆ†æç»“æœ
#[derive(Debug, Clone)]
pub struct UrlAnalysisResult {
    /// è¯­ä¹‰ç†è§£ç»“æœ
    pub semantic_understanding: SemanticUrlResult,
    /// å†…å®¹é¢„æµ‹
    pub content_prediction: ContentPrediction,
    /// è´¨é‡è¯„ä¼°
    pub quality_assessment: UrlQualityAssessment,
    /// ç›¸å…³æ€§åˆ†æ•° (0.0-1.0)
    pub relevance_score: f32,
    /// ç½®ä¿¡åº¦ (0.0-1.0)
    pub confidence: f32,
    /// åˆ†ææ—¶é—´æˆ³
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

/// è¯­ä¹‰URLç†è§£ç»“æœ
#[derive(Debug, Clone)]
pub struct SemanticUrlResult {
    /// URLç±»å‹
    pub url_type: UrlType,
    /// ä¸»é¢˜æ ‡ç­¾
    pub topics: Vec<String>,
    /// ç¼–ç¨‹è¯­è¨€
    pub programming_languages: Vec<String>,
    /// æŠ€æœ¯æ ˆ
    pub tech_stack: Vec<String>,
    /// å†…å®¹ç±»åˆ«
    pub content_category: ContentCategory,
    /// ç›®æ ‡å—ä¼—
    pub target_audience: Vec<String>,
    /// éš¾åº¦çº§åˆ« (1-5)
    pub difficulty_level: u8,
}

/// URLç±»å‹
#[derive(Debug, Clone)]
pub enum UrlType {
    Documentation,
    Tutorial,
    ApiReference,
    Example,
    Blog,
    Forum,
    Repository,
    Package,
    Tool,
    Other,
}

/// å†…å®¹ç±»åˆ«
#[derive(Debug, Clone)]
pub enum ContentCategory {
    GettingStarted,
    Advanced,
    Reference,
    Tutorial,
    Example,
    Troubleshooting,
    BestPractices,
    News,
    Community,
    Other,
}

/// å†…å®¹é¢„æµ‹
#[derive(Debug, Clone)]
pub struct ContentPrediction {
    /// é¢„æµ‹çš„å†…å®¹ç±»å‹
    pub predicted_content_type: Vec<PredictedContentType>,
    /// é¢„æœŸå†…å®¹è´¨é‡ (0.0-1.0)
    pub expected_quality: f32,
    /// é¢„æœŸæœ‰ç”¨æ€§ (0.0-1.0)
    pub expected_usefulness: f32,
    /// é¢„æœŸæ—¶æ•ˆæ€§ (0.0-1.0)
    pub expected_freshness: f32,
    /// å¯èƒ½åŒ…å«çš„ä¿¡æ¯
    pub likely_information: Vec<String>,
    /// æ½œåœ¨é—®é¢˜
    pub potential_issues: Vec<String>,
}

/// é¢„æµ‹çš„å†…å®¹ç±»å‹
#[derive(Debug, Clone)]
pub struct PredictedContentType {
    /// å†…å®¹ç±»å‹
    pub content_type: String,
    /// ç½®ä¿¡åº¦ (0.0-1.0)
    pub confidence: f32,
    /// æè¿°
    pub description: String,
}

/// URLè´¨é‡è¯„ä¼°
#[derive(Debug, Clone)]
pub struct UrlQualityAssessment {
    /// åŸŸåæƒå¨æ€§ (0.0-1.0)
    pub domain_authority: f32,
    /// URLç»“æ„è´¨é‡ (0.0-1.0)
    pub url_structure_quality: f32,
    /// è¯­è¨€ä¸€è‡´æ€§ (0.0-1.0)
    pub language_consistency: f32,
    /// å¯ä¿¡åº¦ (0.0-1.0)
    pub trustworthiness: f32,
    /// è´¨é‡æŒ‡æ ‡
    pub quality_indicators: Vec<QualityIndicator>,
    /// é£é™©å› ç´ 
    pub risk_factors: Vec<RiskFactor>,
}

/// è´¨é‡æŒ‡æ ‡
#[derive(Debug, Clone)]
pub struct QualityIndicator {
    /// æŒ‡æ ‡åç§°
    pub name: String,
    /// åˆ†æ•° (0.0-1.0)
    pub score: f32,
    /// æè¿°
    pub description: String,
}

/// é£é™©å› ç´ 
#[derive(Debug, Clone)]
pub struct RiskFactor {
    /// é£é™©ç±»å‹
    pub risk_type: RiskType,
    /// ä¸¥é‡ç¨‹åº¦ (1-5)
    pub severity: u8,
    /// æè¿°
    pub description: String,
}

/// é£é™©ç±»å‹
#[derive(Debug, Clone)]
pub enum RiskType {
    Security,
    Outdated,
    LowQuality,
    Spam,
    Malicious,
    Other,
}

/// URLæ¯”è¾ƒç»“æœ
#[derive(Debug, Clone)]
pub struct UrlComparisonResult {
    /// è¯­ä¹‰ç›¸ä¼¼åº¦ (0.0-1.0)
    pub semantic_similarity: f32,
    /// å†…å®¹ç›¸ä¼¼åº¦ (0.0-1.0)
    pub content_similarity: f32,
    /// è´¨é‡å·®å¼‚
    pub quality_difference: f32,
    /// æ¨èé€‰æ‹©
    pub recommendation: UrlRecommendation,
    /// æ¯”è¾ƒè¯´æ˜
    pub explanation: String,
}

/// URLæ¨è
#[derive(Debug, Clone)]
pub enum UrlRecommendation {
    PreferFirst,
    PreferSecond,
    BothGood,
    BothPoor,
    Equivalent,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UrlSemanticAnalysis {
    pub url: String,
    pub semantic_meaning: String,
    pub confidence: f64,
    pub related_concepts: Vec<String>,
    pub domain_relevance: f64,
    pub path_analysis: Vec<String>,
    pub query_parameters: HashMap<String, String>,
    pub content_type_prediction: String,
    pub security_assessment: String,
    pub accessibility_score: f64,
    pub url_type: String,
    pub topics: Vec<String>,
    pub programming_languages: Vec<String>,
    pub tech_stack: Vec<String>,
    pub content_category: String,
    pub target_audience: String,
    pub difficulty_level: String,
}

impl UrlAI {
    /// åˆ›å»ºæ–°çš„AI URLåˆ†æå™¨
    pub async fn new(ai_service: AIService) -> Result<Self> {
        let prompts = UrlPrompts::new();
        
        Ok(Self {
            ai_service,
            prompts,
            analysis_cache: std::sync::Arc::new(tokio::sync::RwLock::new(HashMap::new())),
        })
    }

    /// æ™ºèƒ½URLåˆ†æ
    pub async fn analyze_url(&self, url: &str, target_language: &str, query_context: &str) -> Result<UrlAnalysisResult> {
        info!("ğŸ” å¼€å§‹æ™ºèƒ½URLåˆ†æ: {}", url);

        // æ£€æŸ¥ç¼“å­˜
        let cache_key = format!("{}:{}:{}", url, target_language, query_context);
        if let Some(cached) = self.get_cached_result(&cache_key).await {
            debug!("ğŸ¯ ä½¿ç”¨ç¼“å­˜çš„URLåˆ†æç»“æœ");
            return Ok(cached);
        }

        // è§£æURL
        let parsed_url = Url::parse(url)?;
        
        // è¯­ä¹‰ç†è§£
        let semantic_result = self.semantic_url_understanding(&parsed_url, target_language, query_context).await?;
        
        // å†…å®¹é¢„æµ‹
        let content_prediction = self.predict_content(&parsed_url, target_language, &semantic_result).await?;
        
        // è´¨é‡è¯„ä¼°
        let quality_assessment = self.assess_url_quality(&parsed_url, target_language, &semantic_result).await?;
        
        // è®¡ç®—æ•´ä½“ç›¸å…³æ€§å’Œç½®ä¿¡åº¦
        let relevance_score = self.calculate_relevance_score(&semantic_result, &content_prediction, query_context);
        let confidence = self.calculate_confidence(&semantic_result, &content_prediction, &quality_assessment);

        let result = UrlAnalysisResult {
            semantic_understanding: semantic_result,
            content_prediction,
            quality_assessment,
            relevance_score,
            confidence,
            timestamp: chrono::Utc::now(),
        };

        // ç¼“å­˜ç»“æœ
        self.cache_result(&cache_key, &result).await;
        
        Ok(result)
    }

    /// è¯­ä¹‰URLç†è§£
    pub async fn semantic_url_understanding(&self, url: &Url, target_language: &str, query_context: &str) -> Result<SemanticUrlResult> {
        info!("ğŸ§  å¼€å§‹è¯­ä¹‰URLç†è§£");

        let system_prompt = self.prompts.get_semantic_understanding_system_prompt();
        let user_message = self.prompts.get_semantic_understanding_user_prompt(url.as_str(), target_language, query_context);

        let ai_request = AIRequest {
            model: None,
            system_prompt: Some(system_prompt),
            user_message,
            temperature: Some(0.2),
            max_tokens: Some(2000),
            stream: false,
        };

        let ai_response = self.ai_service.request(ai_request).await?;
        
        self.parse_semantic_understanding_response(&ai_response.content).await
    }

    /// å†…å®¹é¢„æµ‹
    pub async fn predict_content(&self, url: &Url, target_language: &str, semantic_result: &SemanticUrlResult) -> Result<ContentPrediction> {
        info!("ğŸ”® å¼€å§‹å†…å®¹é¢„æµ‹");

        let system_prompt = self.prompts.get_content_prediction_system_prompt();
        let user_message = self.prompts.get_content_prediction_user_prompt(url.as_str(), target_language, semantic_result);

        let ai_request = AIRequest {
            model: None,
            system_prompt: Some(system_prompt),
            user_message,
            temperature: Some(0.3),
            max_tokens: Some(2500),
            stream: false,
        };

        let ai_response = self.ai_service.request(ai_request).await?;
        
        self.parse_content_prediction_response(&ai_response.content).await
    }

    /// URLè´¨é‡è¯„ä¼°
    pub async fn assess_url_quality(&self, url: &Url, target_language: &str, semantic_result: &SemanticUrlResult) -> Result<UrlQualityAssessment> {
        info!("ğŸ“Š å¼€å§‹URLè´¨é‡è¯„ä¼°");

        let system_prompt = self.prompts.get_quality_assessment_system_prompt();
        let user_message = self.prompts.get_quality_assessment_user_prompt(url.as_str(), target_language, semantic_result);

        let ai_request = AIRequest {
            model: None,
            system_prompt: Some(system_prompt),
            user_message,
            temperature: Some(0.1),
            max_tokens: Some(2000),
            stream: false,
        };

        let ai_response = self.ai_service.request(ai_request).await?;
        
        self.parse_quality_assessment_response(&ai_response.content).await
    }

    /// æ¯”è¾ƒå¤šä¸ªURL
    pub async fn compare_urls(&self, urls: &[String], target_language: &str, query_context: &str) -> Result<Vec<UrlComparisonResult>> {
        info!("âš–ï¸ å¼€å§‹æ¯”è¾ƒå¤šä¸ªURL");

        let system_prompt = self.prompts.get_comparison_system_prompt();
        let user_message = self.prompts.get_comparison_user_prompt(urls, target_language, query_context);

        let ai_request = AIRequest {
            model: None,
            system_prompt: Some(system_prompt),
            user_message,
            temperature: Some(0.2),
            max_tokens: Some(3000),
            stream: false,
        };

        let ai_response = self.ai_service.request(ai_request).await?;
        
        self.parse_comparison_response(&ai_response.content).await
    }

    /// ç”ŸæˆURLå»ºè®®
    pub async fn suggest_urls(&self, query: &str, target_language: &str, preferences: &HashMap<String, String>) -> Result<Vec<String>> {
        info!("ğŸ’¡ ç”ŸæˆURLå»ºè®®");

        let system_prompt = self.prompts.get_suggestion_system_prompt();
        let user_message = self.prompts.get_suggestion_user_prompt(query, target_language, preferences);

        let ai_request = AIRequest {
            model: None,
            system_prompt: Some(system_prompt),
            user_message,
            temperature: Some(0.4),
            max_tokens: Some(2000),
            stream: false,
        };

        let ai_response = self.ai_service.request(ai_request).await?;
        
        self.parse_suggestion_response(&ai_response.content).await
    }

    /// è§£æè¯­ä¹‰ç†è§£å“åº”
    async fn parse_semantic_understanding_response(&self, response: &str) -> Result<SemanticUrlResult> {
        if let Ok(json_value) = serde_json::from_str::<Value>(response) {
            let url_type = match json_value.get("url_type").and_then(|v| v.as_str()).unwrap_or("other") {
                "documentation" => UrlType::Documentation,
                "tutorial" => UrlType::Tutorial,
                "api_reference" => UrlType::ApiReference,
                "example" => UrlType::Example,
                "blog" => UrlType::Blog,
                "forum" => UrlType::Forum,
                "repository" => UrlType::Repository,
                "package" => UrlType::Package,
                "tool" => UrlType::Tool,
                _ => UrlType::Other,
            };

            let topics = json_value.get("topics")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())
                .unwrap_or_default();

            let programming_languages = json_value.get("programming_languages")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())
                .unwrap_or_default();

            let tech_stack = json_value.get("tech_stack")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())
                .unwrap_or_default();

            let content_category = match json_value.get("content_category").and_then(|v| v.as_str()).unwrap_or("other") {
                "getting_started" => ContentCategory::GettingStarted,
                "advanced" => ContentCategory::Advanced,
                "reference" => ContentCategory::Reference,
                "tutorial" => ContentCategory::Tutorial,
                "example" => ContentCategory::Example,
                "troubleshooting" => ContentCategory::Troubleshooting,
                "best_practices" => ContentCategory::BestPractices,
                "news" => ContentCategory::News,
                "community" => ContentCategory::Community,
                _ => ContentCategory::Other,
            };

            let mut target_audience: Vec<String> = Vec::new();
            if let Some(audience) = json_value.get("target_audience") {
                if let Some(audience_array) = audience.as_array() {
                    target_audience = audience_array.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect();
                }
            }

            let _difficulty_level = json_value.get("difficulty_level")
                .and_then(|v| v.as_u64())
                .unwrap_or(3) as u8;

            Ok(SemanticUrlResult {
                url_type,
                topics,
                programming_languages,
                tech_stack,
                content_category,
                target_audience,
                difficulty_level: _difficulty_level,
            })
        } else {
            // åŸºäºæ–‡æœ¬å†…å®¹çš„è§£æ
            Ok(SemanticUrlResult {
                url_type: UrlType::Other,
                topics: vec!["programming".to_string()],
                programming_languages: Vec::new(),
                tech_stack: Vec::new(),
                content_category: ContentCategory::Other,
                target_audience: vec!["developers".to_string()],
                difficulty_level: 3,
            })
        }
    }

    /// è§£æå†…å®¹é¢„æµ‹å“åº”
    async fn parse_content_prediction_response(&self, response: &str) -> Result<ContentPrediction> {
        if let Ok(json_value) = serde_json::from_str::<Value>(response) {
            let predicted_content_type = json_value.get("predicted_content_type")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|item| {
                    Some(PredictedContentType {
                        content_type: item.get("type").and_then(|v| v.as_str()).unwrap_or("").to_string(),
                        confidence: item.get("confidence").and_then(|v| v.as_f64()).unwrap_or(0.5) as f32,
                        description: item.get("description").and_then(|v| v.as_str()).unwrap_or("").to_string(),
                    })
                }).collect())
                .unwrap_or_default();

            let expected_quality = json_value.get("expected_quality")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.7) as f32;

            let expected_usefulness = json_value.get("expected_usefulness")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.7) as f32;

            let expected_freshness = json_value.get("expected_freshness")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.6) as f32;

            let likely_information = json_value.get("likely_information")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())
                .unwrap_or_default();

            let potential_issues = json_value.get("potential_issues")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())
                .unwrap_or_default();

            Ok(ContentPrediction {
                predicted_content_type,
                expected_quality,
                expected_usefulness,
                expected_freshness,
                likely_information,
                potential_issues,
            })
        } else {
            // åŸºäºæ–‡æœ¬å†…å®¹çš„è§£æ
            Ok(ContentPrediction {
                predicted_content_type: vec![PredictedContentType {
                    content_type: "documentation".to_string(),
                    confidence: 0.6,
                    description: "General documentation content".to_string(),
                }],
                expected_quality: 0.7,
                expected_usefulness: 0.7,
                expected_freshness: 0.6,
                likely_information: vec!["Code examples".to_string(), "API documentation".to_string()],
                potential_issues: Vec::new(),
            })
        }
    }

    /// è§£æè´¨é‡è¯„ä¼°å“åº”
    async fn parse_quality_assessment_response(&self, response: &str) -> Result<UrlQualityAssessment> {
        if let Ok(json_value) = serde_json::from_str::<Value>(response) {
            let domain_authority = json_value.get("domain_authority")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.7) as f32;

            let url_structure_quality = json_value.get("url_structure_quality")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.7) as f32;

            let language_consistency = json_value.get("language_consistency")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.8) as f32;

            let trustworthiness = json_value.get("trustworthiness")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.7) as f32;

            Ok(UrlQualityAssessment {
                domain_authority,
                url_structure_quality,
                language_consistency,
                trustworthiness,
                quality_indicators: Vec::new(),
                risk_factors: Vec::new(),
            })
        } else {
            // åŸºäºæ–‡æœ¬å†…å®¹çš„è§£æ
            Ok(UrlQualityAssessment {
                domain_authority: 0.7,
                url_structure_quality: 0.7,
                language_consistency: 0.8,
                trustworthiness: 0.7,
                quality_indicators: Vec::new(),
                risk_factors: Vec::new(),
            })
        }
    }

    /// è§£ææ¯”è¾ƒå“åº”
    async fn parse_comparison_response(&self, response: &str) -> Result<Vec<UrlComparisonResult>> {
        // å®ç”¨çš„å®ç°
        Ok(Vec::new())
    }

    /// è§£æå»ºè®®å“åº”
    async fn parse_suggestion_response(&self, response: &str) -> Result<Vec<String>> {
        if let Ok(json_value) = serde_json::from_str::<Value>(response) {
            if let Some(suggestions) = json_value.get("suggestions").and_then(|v| v.as_array()) {
                Ok(suggestions.iter()
                    .filter_map(|v| v.as_str().map(|s| s.to_string()))
                    .collect())
            } else {
                Ok(Vec::new())
            }
        } else {
            // åŸºäºæ–‡æœ¬å†…å®¹çš„è§£æï¼šæŒ‰è¡Œåˆ†å‰²
            Ok(response.lines()
                .filter(|line| !line.trim().is_empty() && line.starts_with("http"))
                .map(|line| line.trim().to_string())
                .collect())
        }
    }

    /// è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
    fn calculate_relevance_score(&self, semantic: &SemanticUrlResult, prediction: &ContentPrediction, query_context: &str) -> f32 {
        let mut score = 0.0;
        
        // åŸºäºè¯­ä¹‰ç†è§£çš„ç›¸å…³æ€§
        if !semantic.topics.is_empty() {
            score += 0.3;
        }
        
        // åŸºäºå†…å®¹é¢„æµ‹çš„ç›¸å…³æ€§
        score += prediction.expected_usefulness * 0.4;
        
        // åŸºäºæŸ¥è¯¢ä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§
        if !query_context.is_empty() {
            score += 0.3;
        }
        
        score.min(1.0)
    }

    /// è®¡ç®—ç½®ä¿¡åº¦
    fn calculate_confidence(&self, semantic: &SemanticUrlResult, prediction: &ContentPrediction, quality: &UrlQualityAssessment) -> f32 {
        let semantic_confidence = if semantic.topics.len() > 0 { 0.8 } else { 0.5 };
        let prediction_confidence = prediction.expected_quality;
        let quality_confidence = (quality.domain_authority + quality.trustworthiness) / 2.0;
        
        (semantic_confidence + prediction_confidence + quality_confidence) / 3.0
    }

    /// è·å–ç¼“å­˜ç»“æœ
    async fn get_cached_result(&self, cache_key: &str) -> Option<UrlAnalysisResult> {
        let cache = self.analysis_cache.read().await;
        cache.get(cache_key).cloned()
    }

    /// ç¼“å­˜ç»“æœ
    async fn cache_result(&self, cache_key: &str, result: &UrlAnalysisResult) {
        let mut cache = self.analysis_cache.write().await;
        cache.insert(cache_key.to_string(), result.clone());
        
        // é™åˆ¶ç¼“å­˜å¤§å°
        if cache.len() > 500 {
            // ç§»é™¤ä¸€äº›æ—§çš„æ¡ç›®
            let keys_to_remove: Vec<String> = cache.keys().take(50).cloned().collect();
            for key in keys_to_remove {
                cache.remove(&key);
            }
        }
    }

    /// æ¸…ç†ç¼“å­˜
    pub async fn clear_cache(&self) {
        let mut cache = self.analysis_cache.write().await;
        cache.clear();
        info!("ğŸ§¹ URLåˆ†æç¼“å­˜å·²æ¸…ç†");
    }

    /// è·å–ç¼“å­˜ç»Ÿè®¡
    pub async fn get_cache_stats(&self) -> usize {
        let cache = self.analysis_cache.read().await;
        cache.len()
    }

    async fn parse_url_semantic_response(&self, content: &str) -> Result<UrlSemanticAnalysis> {
        // å®Œæ•´çš„JSONè§£æå®ç°
        if let Ok(parsed_json) = serde_json::from_str::<serde_json::Value>(content) {
            let url_type = parsed_json.get("url_type")
                .and_then(|v| v.as_str())
                .unwrap_or("unknown")
                .to_string();
            
            let topics = parsed_json.get("topics")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter()
                    .filter_map(|v| v.as_str())
                    .map(|s| s.to_string())
                    .collect())
                .unwrap_or_else(Vec::new);
            
            let programming_languages = parsed_json.get("programming_languages")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter()
                    .filter_map(|v| v.as_str())
                    .map(|s| s.to_string())
                    .collect())
                .unwrap_or_else(Vec::new);
            
            let tech_stack = parsed_json.get("tech_stack")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter()
                    .filter_map(|v| v.as_str())
                    .map(|s| s.to_string())
                    .collect())
                .unwrap_or_else(Vec::new);
            
            let content_category = parsed_json.get("content_category")
                .and_then(|v| v.as_str())
                .unwrap_or("general")
                .to_string();
            
            let target_audience = parsed_json.get("target_audience")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter()
                    .filter_map(|v| v.as_str())
                    .map(|s| s.to_string())
                    .collect())
                .unwrap_or_else(Vec::new);
            
            let _difficulty_level = parsed_json.get("difficulty_level")
                .and_then(|v| v.as_i64())
                .unwrap_or(1) as u32;
            
            Ok(UrlSemanticAnalysis {
                url: "unknown".to_string(),
                semantic_meaning: "Text-based semantic analysis".to_string(),
                confidence: 0.6,
                related_concepts: topics.clone(),
                domain_relevance: 0.5,
                path_analysis: vec!["/text".to_string(), "/analysis".to_string()],
                query_parameters: HashMap::new(),
                content_type_prediction: "text/plain".to_string(),
                security_assessment: "unknown".to_string(),
                accessibility_score: 0.5,
                url_type,
                topics,
                programming_languages,
                tech_stack,
                content_category,
                target_audience: target_audience.join(", "),
                difficulty_level: _difficulty_level.to_string(),
            })
        } else {
            // å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬è§£æä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            let analysis = self.parse_url_semantic_from_text(content)?;
            Ok(analysis)
        }
    }

    /// ä»æ–‡æœ¬å†…å®¹è§£æURLè¯­ä¹‰åˆ†æç»“æœï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    fn parse_url_semantic_from_text(&self, content: &str) -> Result<UrlSemanticAnalysis> {
        let mut url_type = "unknown".to_string();
        let mut topics = Vec::new();
        let mut programming_languages = Vec::new();
        let mut tech_stack = Vec::new();
        let mut content_category = "general".to_string();
        let mut target_audience: Vec<String> = Vec::new();
        let mut _difficulty_level = 1u32;

        // åˆ†æå†…å®¹ç¡®å®šURLç±»å‹
        let content_lower = content.to_lowercase();
        if content_lower.contains("documentation") || content_lower.contains("docs") {
            url_type = "documentation".to_string();
        } else if content_lower.contains("tutorial") || content_lower.contains("guide") {
            url_type = "tutorial".to_string();
        } else if content_lower.contains("api") || content_lower.contains("reference") {
            url_type = "api_reference".to_string();
        } else if content_lower.contains("example") || content_lower.contains("demo") {
            url_type = "example".to_string();
        }

        // æå–ç¼–ç¨‹è¯­è¨€å…³é”®è¯
        let language_keywords = vec![
            "rust", "python", "javascript", "typescript", "java", "go", 
            "c++", "c#", "php", "ruby", "swift", "kotlin"
        ];
        
        for keyword in language_keywords {
            if content_lower.contains(keyword) {
                programming_languages.push(keyword.to_string());
            }
        }

        // æå–æŠ€æœ¯æ ˆå…³é”®è¯
        let tech_keywords = vec![
            "react", "vue", "angular", "node", "express", "django", "flask",
            "spring", "tokio", "actix", "serde", "reqwest", "async", "await"
        ];
        
        for keyword in tech_keywords {
            if content_lower.contains(keyword) {
                tech_stack.push(keyword.to_string());
            }
        }

        // åŸºäºå†…å®¹å¤æ‚åº¦ä¼°ç®—éš¾åº¦çº§åˆ«
        let word_count = content.split_whitespace().count();
        _difficulty_level = match word_count {
            0..=50 => 1,
            51..=200 => 2,
            201..=500 => 3,
            501..=1000 => 4,
            _ => 5,
        };

        // æå–ä¸»é¢˜ï¼ˆåŸºäºå…³é”®è¯é¢‘ç‡ï¼‰
        let topic_keywords = vec![
            "async", "programming", "web", "api", "database", "security", 
            "testing", "deployment", "performance", "architecture"
        ];
        
        for keyword in topic_keywords {
            if content_lower.contains(keyword) {
                topics.push(keyword.to_string());
            }
        }

        Ok(UrlSemanticAnalysis {
            url: "unknown".to_string(),
            semantic_meaning: "Text-based semantic analysis".to_string(),
            confidence: 0.6,
            related_concepts: topics.clone(),
            domain_relevance: 0.5,
            path_analysis: vec!["/text".to_string(), "/analysis".to_string()],
            query_parameters: HashMap::new(),
            content_type_prediction: "text/plain".to_string(),
            security_assessment: "unknown".to_string(),
            accessibility_score: 0.5,
            url_type,
            topics,
            programming_languages,
            tech_stack,
            content_category,
            target_audience: target_audience.join(", "),
            difficulty_level: _difficulty_level.to_string(),
        })
    }
} 