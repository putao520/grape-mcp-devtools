use std::time::{Duration, Instant};
use anyhow::Result;
use serde_json::json;

use crate::tools::base::{FileVectorizer, DocumentVector, FileDocumentFragment, FileVectorMetadata};
use crate::vectorization::{VectorizationPerformanceOptimizer, PerformanceConfig, PerformanceMonitor};

/// æ¨¡æ‹Ÿå‘é‡åŒ–å™¨ï¼Œç”¨äºæµ‹è¯•
struct MockVectorizer {
    delay_ms: u64,
}

impl MockVectorizer {
    fn new(delay_ms: u64) -> Self {
        Self { delay_ms }
    }
}

#[async_trait::async_trait]
impl FileVectorizer for MockVectorizer {
    async fn vectorize_file(&self, fragment: &FileDocumentFragment) -> Result<DocumentVector> {
        // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(self.delay_ms)).await;
        
        // ç”Ÿæˆæ¨¡æ‹Ÿå‘é‡
        let vector_data = vec![0.1, 0.2, 0.3, 0.4, 0.5]; // 5ç»´å‘é‡
        
        Ok(DocumentVector {
            data: vector_data,
            dimension: 5,
            metadata: FileVectorMetadata {
                doc_id: fragment.id.clone(),
                language: fragment.language.clone(),
                package_name: fragment.package_name.clone(),
                version: fragment.version.clone(),
                file_path: fragment.file_path.clone(),
                hierarchy_path: fragment.hierarchy_path.clone(),
                keywords: vec!["test".to_string(), "mock".to_string()],
                content_hash: "mock_hash".to_string(),
                content_length: fragment.content.len(),
                created_at: std::time::SystemTime::now(),
                updated_at: std::time::SystemTime::now(),
            },
        })
    }

    async fn vectorize_files_batch(&self, fragments: &[FileDocumentFragment]) -> Result<Vec<DocumentVector>> {
        let mut results = Vec::new();
        for fragment in fragments {
            results.push(self.vectorize_file(fragment).await?);
        }
        Ok(results)
    }

    async fn vectorize_query(&self, _query: &str) -> Result<Vec<f32>> {
        tokio::time::sleep(Duration::from_millis(self.delay_ms)).await;
        Ok(vec![0.1, 0.2, 0.3, 0.4, 0.5])
    }
}

/// åˆ›å»ºæµ‹è¯•æ–‡æ¡£ç‰‡æ®µ
fn create_test_fragments(count: usize) -> Vec<FileDocumentFragment> {
    (0..count)
        .map(|i| FileDocumentFragment {
            id: format!("rust/test-package-{}/1.0.0/src/lib{}.rs", i, i),
            package_name: format!("test-package-{}", i),
            version: "1.0.0".to_string(),
            language: "rust".to_string(),
            file_path: format!("src/lib{}.rs", i),
            content: format!("// Test file {}\npub fn test_function_{}() {{}}", i, i),
            hierarchy_path: vec!["src".to_string(), format!("lib{}.rs", i)],
            file_type: crate::tools::base::FileType::Source,
            created_at: std::time::SystemTime::now(),
        })
        .collect()
}

/// æµ‹è¯•åŸºæœ¬æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
#[tokio::test]
async fn test_basic_performance_optimization() -> Result<()> {
    println!("âš¡ æµ‹è¯•åŸºæœ¬æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½");

    let mock_vectorizer = MockVectorizer::new(50); // 50mså»¶è¿Ÿ
    let config = PerformanceConfig {
        batch_size: 10,
        max_concurrent: 5,
        cache_size: 100,
        cache_ttl_secs: 300,
        warmup_cache_size: 20,
        enable_metrics: true,
    };

    let optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(5);

    // ç¬¬ä¸€æ¬¡å‘é‡åŒ–ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    let start_time = Instant::now();
    let results1 = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    let first_duration = start_time.elapsed();

    assert_eq!(results1.len(), 5);
    println!("âœ… ç¬¬ä¸€æ¬¡æ‰¹é‡å‘é‡åŒ–å®Œæˆï¼Œè€—æ—¶: {:?}", first_duration);

    // ç¬¬äºŒæ¬¡å‘é‡åŒ–ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    let start_time = Instant::now();
    let results2 = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    let second_duration = start_time.elapsed();

    assert_eq!(results2.len(), 5);
    println!("âœ… ç¬¬äºŒæ¬¡æ‰¹é‡å‘é‡åŒ–å®Œæˆï¼Œè€—æ—¶: {:?}", second_duration);

    // ç¬¬äºŒæ¬¡åº”è¯¥æ˜æ˜¾æ›´å¿«ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    assert!(second_duration < first_duration / 2);

    // æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
    let metrics = optimizer.get_metrics().await;
    println!("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:");
    println!("  - æ€»å¤„ç†æ–‡ä»¶æ•°: {}", metrics.total_files_processed);
    println!("  - ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {}", metrics.cache_hits);
    println!("  - ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°: {}", metrics.cache_misses);
    println!("  - ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", metrics.cache_hit_rate() * 100.0);
    println!("  - å¹³å‡å¤„ç†æ—¶é—´: {:.2}ms", metrics.avg_processing_time_ms);

    assert!(metrics.cache_hits > 0);
    assert!(metrics.cache_hit_rate() > 0.0);

    Ok(())
}

/// æµ‹è¯•ç¼“å­˜é¢„çƒ­åŠŸèƒ½
#[tokio::test]
async fn test_cache_warmup() -> Result<()> {
    println!("ğŸ”¥ æµ‹è¯•ç¼“å­˜é¢„çƒ­åŠŸèƒ½");

    let mock_vectorizer = MockVectorizer::new(30);
    let config = PerformanceConfig {
        warmup_cache_size: 10,
        ..Default::default()
    };

    let optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(20);

    // é¢„çƒ­ç¼“å­˜
    let warmup_start = Instant::now();
    optimizer.warmup_cache(&test_fragments).await?;
    let warmup_duration = warmup_start.elapsed();
    println!("âœ… ç¼“å­˜é¢„çƒ­å®Œæˆï¼Œè€—æ—¶: {:?}", warmup_duration);

    // æµ‹è¯•é¢„çƒ­åçš„æ€§èƒ½
    let query_start = Instant::now();
    let results = optimizer.vectorize_files_batch_optimized(&test_fragments[..5]).await?;
    let query_duration = query_start.elapsed();

    assert_eq!(results.len(), 5);
    println!("âœ… é¢„çƒ­åæŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {:?}", query_duration);

    // æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
    let cache_stats = optimizer.get_cache_stats().await;
    println!("ğŸ“Š ç¼“å­˜ç»Ÿè®¡:");
    for (key, value) in cache_stats {
        println!("  - {}: {}", key, value);
    }

    let metrics = optimizer.get_metrics().await;
    assert!(metrics.cache_hits > 0);

    Ok(())
}

/// æµ‹è¯•å¹¶å‘æ§åˆ¶
#[tokio::test]
async fn test_concurrency_control() -> Result<()> {
    println!("ğŸ”„ æµ‹è¯•å¹¶å‘æ§åˆ¶");

    let mock_vectorizer = MockVectorizer::new(100); // è¾ƒé•¿å»¶è¿Ÿ
    let config = PerformanceConfig {
        max_concurrent: 3,
        batch_size: 5,
        ..Default::default()
    };

    let optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(15);

    let start_time = Instant::now();
    let results = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    let duration = start_time.elapsed();

    assert_eq!(results.len(), 15);
    println!("âœ… å¹¶å‘æ§åˆ¶æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {:?}", duration);

    // éªŒè¯å¹¶å‘æ§åˆ¶ç”Ÿæ•ˆï¼ˆåº”è¯¥æ¯”ä¸²è¡Œå¿«ï¼Œä½†ä¸ä¼šå¤ªå¿«ï¼‰
    let expected_min_duration = Duration::from_millis(300); // è‡³å°‘3æ‰¹æ¬¡ * 100ms
    let expected_max_duration = Duration::from_millis(1500); // ä¸åº”è¯¥å¤ªæ…¢
    
    assert!(duration >= expected_min_duration);
    assert!(duration <= expected_max_duration);

    Ok(())
}

/// æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨
#[tokio::test]
async fn test_performance_monitor() -> Result<()> {
    println!("ğŸ“Š æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨");

    let mut monitor = PerformanceMonitor::new();

    // æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
    tokio::time::sleep(Duration::from_millis(50)).await;
    monitor.checkpoint("åˆå§‹åŒ–å®Œæˆ");

    tokio::time::sleep(Duration::from_millis(100)).await;
    monitor.checkpoint("æ•°æ®åŠ è½½å®Œæˆ");

    tokio::time::sleep(Duration::from_millis(75)).await;
    monitor.checkpoint("å¤„ç†å®Œæˆ");

    // æ£€æŸ¥æ€»è€—æ—¶
    let total_duration = monitor.total_duration();
    assert!(total_duration >= Duration::from_millis(225));

    // æ£€æŸ¥æ£€æŸ¥ç‚¹è€—æ—¶
    let checkpoint_durations = monitor.checkpoint_durations();
    assert_eq!(checkpoint_durations.len(), 3);

    println!("âœ… æ€§èƒ½ç›‘æ§å™¨æµ‹è¯•å®Œæˆ");
    monitor.print_report();

    Ok(())
}

/// æµ‹è¯•è‡ªé€‚åº”æ‰¹é‡å¤§å°è°ƒæ•´
#[tokio::test]
async fn test_adaptive_batch_size() -> Result<()> {
    println!("ğŸ¯ æµ‹è¯•è‡ªé€‚åº”æ‰¹é‡å¤§å°è°ƒæ•´");

    let mock_vectorizer = MockVectorizer::new(20);
    let config = PerformanceConfig {
        batch_size: 50,
        ..Default::default()
    };

    let mut optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(10);

    // ç¬¬ä¸€æ¬¡å¤„ç†ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼Œä½å‘½ä¸­ç‡ï¼‰
    let _ = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    
    // è°ƒæ•´æ‰¹é‡å¤§å°
    optimizer.adaptive_batch_size_adjustment().await;
    
    // ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆç¼“å­˜å‘½ä¸­ï¼Œé«˜å‘½ä¸­ç‡ï¼‰
    let _ = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    
    // å†æ¬¡è°ƒæ•´æ‰¹é‡å¤§å°
    optimizer.adaptive_batch_size_adjustment().await;

    let metrics = optimizer.get_metrics().await;
    println!("ğŸ“Š è‡ªé€‚åº”è°ƒæ•´åçš„æŒ‡æ ‡:");
    println!("  - ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", metrics.cache_hit_rate() * 100.0);

    Ok(())
}

/// æµ‹è¯•å¤„ç†æ—¶é—´é¢„æµ‹
#[tokio::test]
async fn test_processing_time_estimation() -> Result<()> {
    println!("â±ï¸ æµ‹è¯•å¤„ç†æ—¶é—´é¢„æµ‹");

    let mock_vectorizer = MockVectorizer::new(40);
    let config = PerformanceConfig::default();

    let optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(5);

    // å¤„ç†ä¸€äº›æ–‡ä»¶ä»¥å»ºç«‹åŸºå‡†
    let _ = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;

    // é¢„æµ‹å¤„ç†æ—¶é—´
    let estimated_time = optimizer.estimate_processing_time(10).await;
    println!("âœ… é¢„æµ‹å¤„ç†10ä¸ªæ–‡ä»¶éœ€è¦: {:?}", estimated_time);

    // å®é™…æµ‹è¯•
    let test_fragments_10 = create_test_fragments(10);
    let start_time = Instant::now();
    let _ = optimizer.vectorize_files_batch_optimized(&test_fragments_10).await?;
    let actual_time = start_time.elapsed();

    println!("âœ… å®é™…å¤„ç†æ—¶é—´: {:?}", actual_time);

    // é¢„æµ‹åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆè€ƒè™‘ç¼“å­˜å‘½ä¸­ï¼‰
    assert!(estimated_time > Duration::from_millis(100));

    Ok(())
}

/// å‹åŠ›æµ‹è¯•
#[tokio::test]
async fn test_stress_performance() -> Result<()> {
    println!("ğŸ’ª å‹åŠ›æµ‹è¯•");

    let mock_vectorizer = MockVectorizer::new(10); // å¿«é€Ÿå¤„ç†
    let config = PerformanceConfig {
        batch_size: 20,
        max_concurrent: 8,
        cache_size: 1000,
        ..Default::default()
    };

    let optimizer = VectorizationPerformanceOptimizer::new(mock_vectorizer, config);
    let test_fragments = create_test_fragments(100); // å¤§é‡æ–‡ä»¶

    let start_time = Instant::now();
    let results = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    let duration = start_time.elapsed();

    assert_eq!(results.len(), 100);
    println!("âœ… å‹åŠ›æµ‹è¯•å®Œæˆï¼Œå¤„ç†100ä¸ªæ–‡ä»¶è€—æ—¶: {:?}", duration);

    // ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆå…¨éƒ¨ç¼“å­˜å‘½ä¸­ï¼‰
    let start_time = Instant::now();
    let results2 = optimizer.vectorize_files_batch_optimized(&test_fragments).await?;
    let cached_duration = start_time.elapsed();

    assert_eq!(results2.len(), 100);
    println!("âœ… ç¼“å­˜å‘½ä¸­æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {:?}", cached_duration);

    // ç¼“å­˜å‘½ä¸­åº”è¯¥æ˜¾è‘—æ›´å¿«
    assert!(cached_duration < duration / 5);

    let metrics = optimizer.get_metrics().await;
    println!("ğŸ“Š å‹åŠ›æµ‹è¯•æŒ‡æ ‡:");
    println!("  - æ€»å¤„ç†æ–‡ä»¶æ•°: {}", metrics.total_files_processed);
    println!("  - ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", metrics.cache_hit_rate() * 100.0);
    println!("  - å¹³å‡å¤„ç†æ—¶é—´: {:.2}ms", metrics.avg_processing_time_ms);
    println!("  - æ‰¹é‡å¤„ç†æ¬¡æ•°: {}", metrics.batch_count);

    Ok(())
} 