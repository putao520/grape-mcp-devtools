//! # Grape MCP DevTools
//!
//! ä¸€ä¸ªåŸºäº MCP (Model Context Protocol) çš„å¤šè¯­è¨€æ–‡æ¡£æœåŠ¡ï¼Œä¸“ä¸º LLM æä¾›æ–‡æ¡£æŸ¥è¯¢å’Œç‰ˆæœ¬æ£€æŸ¥åŠŸèƒ½ã€‚
//! 
//! ## ç‰¹æ€§
//! 
//! - ğŸ” **æ–‡æ¡£æœç´¢** - æœç´¢å„ç§ç¼–ç¨‹è¯­è¨€çš„åŒ…ä¿¡æ¯ã€APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
//! - ğŸ“¦ **ç‰ˆæœ¬æ£€æŸ¥** - è·å–åŒ…çš„æœ€æ–°ç‰ˆæœ¬ã€ç‰ˆæœ¬å†å²å’Œå…¼å®¹æ€§ä¿¡æ¯
//! - ğŸ“š **APIæ–‡æ¡£** - è·å–ç¼–ç¨‹è¯­è¨€APIçš„è¯¦ç»†æ–‡æ¡£ä¿¡æ¯
//! - ğŸš€ **MCPåè®®** - åŸºäºæ ‡å‡†MCPåè®®ï¼Œæ”¯æŒstdioæ¨¡å¼é€šä¿¡
//! 
//! ## å¿«é€Ÿå¼€å§‹
//! 
//! ```rust
//! use grape_mcp_devtools::*;
//! 
//! #[tokio::main]
//! async fn main() -> Result<(), MCPError> {
//!     // åˆ›å»ºMCPæœåŠ¡å™¨
//!     let server = mcp::create_server().await?;
//!     
//!     // å¯åŠ¨æœåŠ¡å™¨
//!     server.run().await?;
//!     
//!     Ok(())
//! }
//! ```

pub mod errors;
pub mod mcp;
pub mod tools;
pub mod versioning;
pub mod cli;
pub mod language_features;
pub mod ai;
pub mod config;
pub mod types;
pub mod storage;
pub mod index;
pub mod query;
pub mod metrics;
pub mod embeddings;

// æ–°å¢ï¼šæ™ºèƒ½MCPæœåŠ¡å™¨æ¨¡å—ï¼ˆåŒè¿›ç¨‹å¤šAgentæ¶æ„ï¼‰
// pub mod intelligent_mcp_server;

pub use errors::{MCPError, MCPResult};
pub use config::*;
pub use types::*;
pub use storage::*;
pub use index::HnswIndex;
pub use query::{QueryEngine, IndexStats as QueryIndexStats};
pub use metrics::*;
pub use embeddings::*;
pub use errors::*;

// æ˜ç¡®æŒ‡å®šSearchResultç±»å‹ï¼Œé¿å…å†²çª
pub use types::SearchResult;

use std::path::PathBuf;
use std::sync::Arc;

/// å‘é‡æ•°æ®åº“ä¸»ç»“æ„
pub struct VectorDatabase {
    storage: Box<dyn VectorStore>,
    query_engine: QueryEngine,
    metrics: Arc<MetricsCollector>,
    config: VectorDbConfig,
}

impl VectorDatabase {
    /// åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“å®ä¾‹
    pub async fn new(data_dir: PathBuf, config: VectorDbConfig) -> Result<Self> {
        let metrics = Arc::new(MetricsCollector::new());
        
        // åˆ›å»ºå­˜å‚¨å±‚
        let storage = Box::new(SledVectorStore::new(data_dir.clone(), &config).await?);
        
        // åˆ›å»ºæŸ¥è¯¢å¼•æ“
        let query_engine = QueryEngine::new(&config, metrics.clone())?;

        Ok(Self {
            storage,
            query_engine,
            metrics,
            config,
        })
    }

    /// ä½¿ç”¨OpenAIå…¼å®¹APIåˆ›å»ºå‘é‡æ•°æ®åº“
    pub async fn with_openai_compatible(
        data_dir: PathBuf,
        endpoint: String,
        api_key: String,
        model: String,
    ) -> Result<Self> {
        let config = VectorDbConfig::with_openai_compatible(endpoint, api_key, model);
        Self::new(data_dir, config).await
    }

    /// ä½¿ç”¨Azure OpenAIåˆ›å»ºå‘é‡æ•°æ®åº“
    pub async fn with_azure_openai(
        data_dir: PathBuf,
        endpoint: String,
        api_key: String,
        deployment_name: String,
        api_version: String,
    ) -> Result<Self> {
        let config = VectorDbConfig::with_azure_openai(endpoint, api_key, deployment_name, api_version);
        Self::new(data_dir, config).await
    }

    /// ä½¿ç”¨Ollamaåˆ›å»ºå‘é‡æ•°æ®åº“
    pub async fn with_ollama(
        data_dir: PathBuf,
        endpoint: String,
        model: String,
    ) -> Result<Self> {
        let config = VectorDbConfig::with_ollama(endpoint, model);
        Self::new(data_dir, config).await
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºå‘é‡æ•°æ®åº“
    pub async fn with_config(data_dir: PathBuf, config: VectorDbConfig) -> Result<Self> {
        Self::new(data_dir, config).await
    }

    /// æ·»åŠ æ–‡æ¡£
    pub async fn add_document(&mut self, document: Document) -> Result<String> {
        let _timer = QueryTimer::new(self.metrics.clone());

        // ç”ŸæˆåµŒå…¥å‘é‡
        let embedding_provider = create_embedding_provider(&self.config.embedding)?;
        let embedding = embedding_provider.generate_embedding(&document.content).await?;
        
        // åˆ›å»ºæ–‡æ¡£è®°å½•
        let record = DocumentRecord {
            id: document.id.clone(),
            title: document.title.unwrap_or_else(|| "æ— æ ‡é¢˜".to_string()),
            content: document.content.clone(),
            embedding,
            package_name: document.package_name.unwrap_or_else(|| "unknown".to_string()),
            doc_type: document.doc_type.unwrap_or_else(|| "unknown".to_string()),
            language: document.language.unwrap_or_else(|| "unknown".to_string()),
            version: document.version.unwrap_or_else(|| "1.0".to_string()),
            metadata: document.metadata.clone(),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        };

        // ä¿å­˜åˆ°å­˜å‚¨
        self.storage.add_document(record.clone()).await?;
        
        // æ·»åŠ åˆ°ç´¢å¼•
        self.query_engine.add_document(&record).await?;

        // æ›´æ–°æŒ‡æ ‡
        let stats = self.storage.stats();
        self.metrics.update_document_count(stats.document_count as u64);

        Ok(document.id)
    }

    /// è·å–æ–‡æ¡£
    pub async fn get_document(&self, id: &str) -> Result<Option<Document>> {
        let _timer = QueryTimer::new(self.metrics.clone());

        if let Some(record) = self.storage.get_document(id).await? {
            self.metrics.record_cache_hit();
            Ok(Some(Document {
                id: record.id,
                title: Some(record.title),
                content: record.content,
                package_name: Some(record.package_name),
                doc_type: Some(record.doc_type),
                language: Some(record.language),
                version: Some(record.version),
                metadata: record.metadata,
            }))
        } else {
            self.metrics.record_cache_miss();
            Ok(None)
        }
    }

    /// åˆ é™¤æ–‡æ¡£
    pub async fn delete_document(&mut self, id: &str) -> Result<bool> {
        let _timer = QueryTimer::new(self.metrics.clone());

        // ä»å­˜å‚¨åˆ é™¤
        let deleted_from_storage = self.storage.delete_document(id).await?;
        
        // ä»ç´¢å¼•åˆ é™¤
        let deleted_from_index = self.query_engine.remove_document(id).await?;

        if deleted_from_storage || deleted_from_index {
            // æ›´æ–°æŒ‡æ ‡
            let stats = self.storage.stats();
            self.metrics.update_document_count(stats.document_count as u64);
        }

        Ok(deleted_from_storage || deleted_from_index)
    }

    /// æ›´æ–°æ–‡æ¡£
    pub async fn update_document(&mut self, document: Document) -> Result<()> {
        let _timer = QueryTimer::new(self.metrics.clone());

        // ç”Ÿæˆæ–°çš„åµŒå…¥å‘é‡
        let embedding_provider = create_embedding_provider(&self.config.embedding)?;
        let embedding = embedding_provider.generate_embedding(&document.content).await?;
        
        // åˆ›å»ºæ›´æ–°çš„æ–‡æ¡£è®°å½•
        let record = DocumentRecord {
            id: document.id.clone(),
            title: document.title.unwrap_or_else(|| "æ— æ ‡é¢˜".to_string()),
            content: document.content.clone(),
            embedding,
            package_name: document.package_name.unwrap_or_else(|| "unknown".to_string()),
            doc_type: document.doc_type.unwrap_or_else(|| "unknown".to_string()),
            language: document.language.unwrap_or_else(|| "unknown".to_string()),
            version: document.version.unwrap_or_else(|| "1.0".to_string()),
            metadata: document.metadata.clone(),
            created_at: chrono::Utc::now(), // è¿™é‡Œåº”è¯¥ä¿ç•™åŸå§‹åˆ›å»ºæ—¶é—´ï¼Œä½†ç®€åŒ–å®ç°
            updated_at: chrono::Utc::now(),
        };

        // æ›´æ–°å­˜å‚¨
        self.storage.update_document(record.clone()).await?;
        
        // æ›´æ–°ç´¢å¼•ï¼ˆå…ˆåˆ é™¤å†æ·»åŠ ï¼‰
        self.query_engine.remove_document(&document.id).await?;
        self.query_engine.add_document(&record).await?;

        Ok(())
    }

    /// å‘é‡æœç´¢
    pub async fn vector_search(&self, query_vector: &[f32], limit: usize) -> Result<Vec<SearchResult>> {
        self.query_engine.vector_search(&*self.storage, query_vector, limit).await
    }

    /// æ–‡æœ¬æœç´¢
    pub async fn text_search(&self, query: &str, limit: usize) -> Result<Vec<SearchResult>> {
        self.query_engine.text_search(&*self.storage, query, limit).await
    }

    /// æ··åˆæœç´¢ï¼ˆå‘é‡ + æ–‡æœ¬ï¼‰
    pub async fn hybrid_search(
        &self,
        query_text: &str,
        limit: usize,
        vector_weight: f32,
        text_weight: f32,
    ) -> Result<Vec<SearchResult>> {
        // ç”ŸæˆæŸ¥è¯¢å‘é‡
        let embedding_provider = create_embedding_provider(&self.config.embedding)?;
        let query_vector = embedding_provider.generate_embedding(query_text).await?;

        self.query_engine.search(
            &*self.storage,
            Some(&query_vector),
            Some(query_text),
            limit,
            vector_weight,
            text_weight,
        ).await
    }

    /// è¯­ä¹‰æœç´¢ï¼ˆåŸºäºæ–‡æœ¬ç”Ÿæˆå‘é‡ï¼‰
    pub async fn semantic_search(&self, query_text: &str, limit: usize) -> Result<Vec<SearchResult>> {
        let embedding_provider = create_embedding_provider(&self.config.embedding)?;
        let query_vector = embedding_provider.generate_embedding(query_text).await?;
        
        self.vector_search(&query_vector, limit).await
    }

    /// ç®€åŒ–çš„æœç´¢æ–¹æ³•ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰
    pub async fn search(&self, query_text: &str, limit: usize) -> Result<Vec<SearchResult>> {
        self.semantic_search(query_text, limit).await
    }

    /// åˆ—å‡ºæ–‡æ¡£
    pub async fn list_documents(&self, offset: usize, limit: usize) -> Result<Vec<Document>> {
        let _timer = QueryTimer::new(self.metrics.clone());

        let records = self.storage.list_documents(offset, limit).await?;
        let documents = records.into_iter().map(|record| Document {
            id: record.id,
            title: Some(record.title),
            content: record.content,
            package_name: Some(record.package_name),
            doc_type: Some(record.doc_type),
            language: Some(record.language),
            version: Some(record.version),
            metadata: record.metadata,
        }).collect();

        Ok(documents)
    }

    /// é‡å»ºç´¢å¼•
    pub async fn rebuild_index(&self) -> Result<()> {
        self.query_engine.rebuild_index().await
    }

    /// ä¿å­˜æ•°æ®åº“
    pub async fn save(&self) -> Result<()> {
        self.storage.save().await
    }

    /// å‹ç¼©æ•°æ®åº“
    pub async fn compact(&self) -> Result<()> {
        self.storage.compact().await
    }

    /// è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> DatabaseStats {
        self.storage.stats()
    }

    /// è·å–æ€§èƒ½æŒ‡æ ‡
    pub fn get_metrics(&self) -> PerformanceMetrics {
        self.metrics.get_metrics()
    }

    /// è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    pub fn get_index_stats(&self) -> QueryIndexStats {
        self.query_engine.get_index_stats()
    }

    /// é‡ç½®æŒ‡æ ‡
    pub fn reset_metrics(&self) {
        self.metrics.reset();
    }

    /// è·å–é…ç½®
    pub fn get_config(&self) -> &VectorDbConfig {
        &self.config
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_vector_database() {
        let temp_dir = TempDir::new().unwrap();
        let config = VectorDbConfig::default();
        
        let mut db = VectorDatabase::new(temp_dir.path().to_path_buf(), config).await.unwrap();

        // æ·»åŠ æ–‡æ¡£
        let doc = Document {
            id: "test1".to_string(),
            title: Some("æµ‹è¯•æ–‡æ¡£".to_string()),
            content: "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£çš„å†…å®¹".to_string(),
            package_name: Some("test_package".to_string()),
            doc_type: Some("test".to_string()),
            ..Default::default()
        };

        let doc_id = db.add_document(doc.clone()).await.unwrap();
        assert_eq!(doc_id, "test1");

        // è·å–æ–‡æ¡£
        let retrieved = db.get_document("test1").await.unwrap();
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().title, Some("æµ‹è¯•æ–‡æ¡£".to_string()));

        // æœç´¢
        let results = db.text_search("æµ‹è¯•", 5).await.unwrap();
        assert!(!results.is_empty());

        // è·å–ç»Ÿè®¡ä¿¡æ¯
        let stats = db.get_stats();
        assert_eq!(stats.document_count, 1);

        // åˆ é™¤æ–‡æ¡£
        let deleted = db.delete_document("test1").await.unwrap();
        assert!(deleted);

        let stats = db.get_stats();
        assert_eq!(stats.document_count, 0);
    }

    #[tokio::test]
    async fn test_semantic_search() {
        let temp_dir = TempDir::new().unwrap();
        let config = VectorDbConfig::default();
        
        let mut db = VectorDatabase::new(temp_dir.path().to_path_buf(), config).await.unwrap();

        // æ·»åŠ ä¸€äº›æµ‹è¯•æ–‡æ¡£
        let docs = vec![
            Document {
                id: "doc1".to_string(),
                title: Some("Rustç¼–ç¨‹è¯­è¨€".to_string()),
                content: "Rustæ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œæ³¨é‡å®‰å…¨æ€§å’Œæ€§èƒ½".to_string(),
                package_name: Some("rust".to_string()),
                doc_type: Some("tutorial".to_string()),
                ..Default::default()
            },
            Document {
                id: "doc2".to_string(),
                title: Some("Pythonæ•°æ®ç§‘å­¦".to_string()),
                content: "Pythonæ˜¯æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„çƒ­é—¨è¯­è¨€".to_string(),
                package_name: Some("python".to_string()),
                doc_type: Some("guide".to_string()),
                ..Default::default()
            },
        ];

        for doc in docs {
            db.add_document(doc).await.unwrap();
        }

        // é‡å»ºç´¢å¼•
        db.rebuild_index().await.unwrap();

        // è¯­ä¹‰æœç´¢
        let results = db.semantic_search("ç¼–ç¨‹è¯­è¨€", 5).await.unwrap();
        assert!(!results.is_empty());
        
        // æ··åˆæœç´¢
        let results = db.hybrid_search("ç¼–ç¨‹", 5, 0.7, 0.3).await.unwrap();
        assert!(!results.is_empty());
    }
}

// Re-export commonly used types
pub use async_trait::async_trait;
pub use serde_json::{json, Value}; 