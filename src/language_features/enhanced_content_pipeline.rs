use anyhow::{anyhow, Result};
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{info, warn, debug, error};
use chrono::{DateTime, Utc};

// ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
use chromiumoxide::{Browser, BrowserConfig, Page};
use kuchiki::traits::*;
use lingua::{Language, LanguageDetector, LanguageDetectorBuilder};
use unicode_normalization::UnicodeNormalization;
use html_escape::decode_html_entities;
use ort::{Environment, ExecutionProvider, GraphOptimizationLevel, SessionBuilder};

// é¡¹ç›®å†…éƒ¨å¯¼å…¥
use crate::errors::GrapeError;

/// ä¼ä¸šçº§å†…å®¹å¤„ç†ç®¡é“
/// 
/// é›†æˆå¤šç§ç¬¬ä¸‰æ–¹æˆç†Ÿåº“å®ç°é«˜è´¨é‡çš„ç½‘é¡µå†…å®¹åˆ†æï¼š
/// - Chromiumæ¸²æŸ“å¼•æ“ï¼šå¤„ç†JavaScriptåŠ¨æ€å†…å®¹
/// - Linguaè¯­è¨€æ£€æµ‹ï¼šç²¾ç¡®è¯†åˆ«å†…å®¹è¯­è¨€
/// - ONNX Runtimeï¼šè¿è¡Œé¢„è®­ç»ƒAIæ¨¡å‹
/// - å¤šçº§å†…å®¹æ¸…ç†ï¼šç¡®ä¿é«˜è´¨é‡è¾“å‡º
#[derive(Clone)]
pub struct EnhancedContentPipeline {
    /// æµè§ˆå™¨å®ä¾‹ï¼ˆç”¨äºJavaScriptæ¸²æŸ“ï¼‰
    browser: Arc<RwLock<Option<Browser>>>,
    /// è¯­è¨€æ£€æµ‹å™¨
    language_detector: Arc<LanguageDetector>,
    /// ONNXè¿è¡Œæ—¶ç¯å¢ƒ
    ort_environment: Arc<Environment>,
    /// å†…å®¹æå–ç­–ç•¥
    extraction_strategies: Vec<Arc<dyn ContentExtractionStrategy>>,
    /// è´¨é‡è¯„ä¼°å™¨
    quality_assessor: Arc<ContentQualityAssessor>,
    /// ç¼“å­˜å±‚
    cache: Arc<RwLock<HashMap<String, CachedContent>>>,
    /// é…ç½®
    config: PipelineConfig,
    /// æŒ‡æ ‡æ”¶é›†å™¨
    metrics: Arc<PipelineMetrics>,
}

/// ç®¡é“é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PipelineConfig {
    /// æ˜¯å¦å¯ç”¨æµè§ˆå™¨æ¸²æŸ“
    pub enable_browser_rendering: bool,
    /// æµè§ˆå™¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    pub browser_timeout_secs: u64,
    /// æœ€å¤§å†…å®¹é•¿åº¦
    pub max_content_length: usize,
    /// è´¨é‡é˜ˆå€¼
    pub quality_threshold: f32,
    /// ç¼“å­˜TTLï¼ˆç§’ï¼‰
    pub cache_ttl_secs: u64,
    /// å¹¶å‘é™åˆ¶
    pub max_concurrent_extractions: usize,
    /// å¯ç”¨çš„æå–ç­–ç•¥
    pub enabled_strategies: Vec<String>,
    /// AIæ¨¡å‹è·¯å¾„
    pub ai_model_paths: HashMap<String, String>,
}

impl Default for PipelineConfig {
    fn default() -> Self {
        Self {
            enable_browser_rendering: true,
            browser_timeout_secs: 30,
            max_content_length: 1_000_000, // 1MB
            quality_threshold: 0.7,
            cache_ttl_secs: 3600,
            max_concurrent_extractions: 10,
            enabled_strategies: vec![
                "readability".to_string(),
                "boilerpipe".to_string(),
                "ai_extraction".to_string(),
                "structured_data".to_string(),
            ],
            ai_model_paths: HashMap::new(),
        }
    }
}

/// å†…å®¹æå–ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContentExtractionResult {
    /// æå–çš„ä¸»è¦å†…å®¹
    pub main_content: String,
    /// æ–‡æ¡£æ ‡é¢˜
    pub title: String,
    /// æ–‡æ¡£æ‘˜è¦
    pub summary: Option<String>,
    /// æ£€æµ‹åˆ°çš„è¯­è¨€
    pub detected_language: Option<Language>,
    /// ç½®ä¿¡åº¦åˆ†æ•°
    pub confidence_score: f32,
    /// è´¨é‡åˆ†æ•°
    pub quality_score: f32,
    /// ç»“æ„åŒ–æ•°æ®
    pub structured_data: HashMap<String, serde_json::Value>,
    /// æå–çš„é“¾æ¥
    pub links: Vec<ExtractedLink>,
    /// æå–çš„å›¾ç‰‡
    pub images: Vec<ExtractedImage>,
    /// ä»£ç å—
    pub code_blocks: Vec<CodeBlock>,
    /// è¡¨æ ¼æ•°æ®
    pub tables: Vec<TableData>,
    /// å…ƒæ•°æ®
    pub metadata: ExtractionMetadata,
}

/// æå–çš„é“¾æ¥
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtractedLink {
    pub url: String,
    pub text: String,
    pub rel: Option<String>,
    pub title: Option<String>,
    pub relevance_score: f32,
}

/// æå–çš„å›¾ç‰‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtractedImage {
    pub url: String,
    pub alt_text: Option<String>,
    pub title: Option<String>,
    pub dimensions: Option<(u32, u32)>,
    pub relevance_score: f32,
}

/// ä»£ç å—
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CodeBlock {
    pub language: Option<String>,
    pub code: String,
    pub line_numbers: Option<Vec<u32>>,
    pub context: Option<String>,
}

/// è¡¨æ ¼æ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TableData {
    pub headers: Vec<String>,
    pub rows: Vec<Vec<String>>,
    pub caption: Option<String>,
    pub context: Option<String>,
}

/// æå–å…ƒæ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtractionMetadata {
    pub extraction_time: DateTime<Utc>,
    pub strategies_used: Vec<String>,
    pub processing_time_ms: u64,
    pub content_source: String,
    pub ai_models_used: Vec<String>,
    pub quality_metrics: QualityMetrics,
}

/// è´¨é‡æŒ‡æ ‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityMetrics {
    pub readability_score: f32,
    pub coherence_score: f32,
    pub completeness_score: f32,
    pub relevance_score: f32,
    pub technical_content_score: f32,
}

/// ç¼“å­˜å†…å®¹
#[derive(Debug, Clone)]
struct CachedContent {
    content: ContentExtractionResult,
    timestamp: DateTime<Utc>,
    access_count: u32,
}

/// å†…å®¹æå–ç­–ç•¥æ¥å£
#[async_trait]
pub trait ContentExtractionStrategy: Send + Sync {
    /// ç­–ç•¥åç§°
    fn name(&self) -> &str;
    
    /// æå–å†…å®¹
    async fn extract(&self, url: &str, html: &str) -> Result<ContentExtractionResult>;
    
    /// ç­–ç•¥ä¼˜å…ˆçº§ï¼ˆè¶Šé«˜è¶Šä¼˜å…ˆï¼‰
    fn priority(&self) -> u8;
    
    /// æ˜¯å¦æ”¯æŒè¯¥URL
    fn supports_url(&self, url: &str) -> bool;
}

/// Readabilityç®—æ³•å®ç°
pub struct ReadabilityStrategy {
    name: String,
}

impl ReadabilityStrategy {
    pub fn new() -> Self {
        Self {
            name: "readability".to_string(),
        }
    }
}

#[async_trait]
impl ContentExtractionStrategy for ReadabilityStrategy {
    fn name(&self) -> &str {
        &self.name
    }

    async fn extract(&self, url: &str, html: &str) -> Result<ContentExtractionResult> {
        debug!("ğŸ” ä½¿ç”¨Readabilityç­–ç•¥æå–å†…å®¹: {}", url);
        
        // ä½¿ç”¨kuchikiè§£æHTML
        let document = kuchiki::parse_html().one(html);
        
        // å¯»æ‰¾ä¸»è¦å†…å®¹å®¹å™¨
        let main_content = self.extract_main_content(&document)?;
        let title = self.extract_title(&document);
        let links = self.extract_links(&document, url)?;
        let images = self.extract_images(&document, url)?;
        
        // è®¡ç®—è´¨é‡åˆ†æ•°
        let quality_score = self.calculate_content_quality_score(&main_content);
        
        Ok(ContentExtractionResult {
            main_content,
            title,
            summary: None,
            detected_language: None,
            confidence_score: 0.8,
            quality_score,
            structured_data: HashMap::new(),
            links,
            images,
            code_blocks: Vec::new(),
            tables: Vec::new(),
            metadata: ExtractionMetadata {
                extraction_time: Utc::now(),
                strategies_used: vec![self.name().to_string()],
                processing_time_ms: 0,
                content_source: url.to_string(),
                ai_models_used: Vec::new(),
                quality_metrics: QualityMetrics {
                    readability_score: quality_score,
                    coherence_score: 0.0,
                    completeness_score: 0.0,
                    relevance_score: 0.0,
                    technical_content_score: 0.0,
                },
            },
        })
    }

    fn priority(&self) -> u8 {
        80
    }

    fn supports_url(&self, _url: &str) -> bool {
        true // æ”¯æŒæ‰€æœ‰URL
    }
}

impl ReadabilityStrategy {
    fn extract_main_content(&self, document: &kuchiki::NodeRef) -> Result<String> {
        // å®ç°å®Œæ•´çš„Readabilityç®—æ³•
        let content_selectors = [
            "main",
            "article", 
            ".content",
            ".main-content",
            ".post-content",
            ".entry-content",
            "#content",
            "#main",
            ".container",
        ];

        let mut best_content = String::new();
        let mut best_score = 0.0;

        for selector in &content_selectors {
            if let Ok(mut elements) = document.select(selector) {
                if let Some(element) = elements.next() {
                    let text = element.text_contents();
                    if text.len() > 100 {
                        let score = self.calculate_content_quality_score(&text);
                        if score > best_score {
                            best_score = score;
                            best_content = self.clean_text(&text);
                        }
                    }
                }
            }
        }

        if !best_content.is_empty() {
            return Ok(best_content);
        }

        // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨bodyä½†è¿›è¡Œæ›´æ™ºèƒ½çš„è¿‡æ»¤
        if let Ok(mut body_elements) = document.select("body") {
            if let Some(body) = body_elements.next() {
                let text = body.text_contents();
                let cleaned = self.clean_text(&text);
                let filtered = self.filter_noise_content(&cleaned);
                return Ok(filtered);
            }
        }

        Err(anyhow!("æ— æ³•æå–ä¸»è¦å†…å®¹"))
    }

    /// è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°ï¼ˆå®Œæ•´çš„Readabilityç®—æ³•ï¼‰
    fn calculate_content_quality_score(&self, content: &str) -> f32 {
        let words = content.split_whitespace().count() as f32;
        let sentences = content.split(&['.', '!', '?'][..]).count() as f32;
        let paragraphs = content.split("\n\n").count() as f32;
        
        // åŸºäºå¤šä¸ªå› ç´ çš„è´¨é‡è¯„ä¼°
        let mut score = 0.0;
        
        // é•¿åº¦åˆ†æ•° (0-30åˆ†)
        if words > 50.0 {
            score += 10.0;
        }
        if words > 200.0 {
            score += 10.0;
        }
        if words > 500.0 {
            score += 10.0;
        }
        
        // ç»“æ„åˆ†æ•° (0-30åˆ†)
        if sentences > 3.0 {
            score += 10.0;
        }
        if paragraphs > 1.0 {
            score += 10.0;
        }
        
        // å¹³å‡å¥é•¿åˆ†æ•° (0-20åˆ†)
        let avg_sentence_length = if sentences > 0.0 { words / sentences } else { 0.0 };
        if avg_sentence_length > 5.0 && avg_sentence_length < 25.0 {
            score += 20.0;
        }
        
        // å†…å®¹å¤šæ ·æ€§åˆ†æ•° (0-20åˆ†)
        let unique_words = content.split_whitespace()
            .map(|w| w.to_lowercase())
            .collect::<std::collections::HashSet<_>>()
            .len() as f32;
        let diversity_ratio = if words > 0.0 { unique_words / words } else { 0.0 };
        if diversity_ratio > 0.3 {
            score += 20.0;
        }
        
        score / 100.0 // å½’ä¸€åŒ–åˆ°0-1
    }

    /// è¿‡æ»¤å™ªå£°å†…å®¹
    fn filter_noise_content(&self, content: &str) -> String {
        let lines: Vec<&str> = content.lines().collect();
        let mut filtered_lines = Vec::new();
        
        for line in lines {
            let trimmed = line.trim();
            
            // è·³è¿‡è¿‡çŸ­çš„è¡Œ
            if trimmed.len() < 10 {
                continue;
            }
            
            // è·³è¿‡å¯èƒ½çš„å¯¼èˆªæˆ–èœå•é¡¹
            if trimmed.split_whitespace().count() < 3 {
                continue;
            }
            
            // è·³è¿‡å¯èƒ½çš„ç‰ˆæƒä¿¡æ¯
            if trimmed.to_lowercase().contains("copyright") || 
               trimmed.to_lowercase().contains("Â©") ||
               trimmed.to_lowercase().contains("all rights reserved") {
                continue;
            }
            
            filtered_lines.push(trimmed);
        }
        
        filtered_lines.join(" ")
    }

    fn extract_title(&self, document: &kuchiki::NodeRef) -> String {
        if let Ok(mut title_elements) = document.select("title") {
            if let Some(title) = title_elements.next() {
                return self.clean_text(&title.text_contents());
            }
        }

        if let Ok(mut h1_elements) = document.select("h1") {
            if let Some(h1) = h1_elements.next() {
                return self.clean_text(&h1.text_contents());
            }
        }

        "æœªçŸ¥æ ‡é¢˜".to_string()
    }

    fn extract_links(&self, document: &kuchiki::NodeRef, base_url: &str) -> Result<Vec<ExtractedLink>> {
        let mut links = Vec::new();
        
        if let Ok(link_elements) = document.select("a[href]") {
            for element in link_elements {
                if let Some(element_ref) = element.as_element() {
                    let attrs = element_ref.attributes.borrow();
                    
                    if let Some(href) = attrs.get("href") {
                        let text = element.text_contents();
                        if !text.trim().is_empty() && !href.starts_with('#') {
                            links.push(ExtractedLink {
                                url: self.resolve_url(href, base_url)?,
                                text: self.clean_text(&text),
                                rel: attrs.get("rel").map(|s| s.to_string()),
                                title: attrs.get("title").map(|s| s.to_string()),
                                relevance_score: 0.5,
                            });
                        }
                    }
                }
            }
        }

        Ok(links)
    }

    fn extract_images(&self, document: &kuchiki::NodeRef, base_url: &str) -> Result<Vec<ExtractedImage>> {
        let mut images = Vec::new();
        
        if let Ok(img_elements) = document.select("img[src]") {
            for element in img_elements {
                if let Some(element_ref) = element.as_element() {
                    let attrs = element_ref.attributes.borrow();
                    
                    if let Some(src) = attrs.get("src") {
                        images.push(ExtractedImage {
                            url: self.resolve_url(src, base_url)?,
                            alt_text: attrs.get("alt").map(|s| s.to_string()),
                            title: attrs.get("title").map(|s| s.to_string()),
                            dimensions: None,
                            relevance_score: 0.5,
                        });
                    }
                }
            }
        }

        Ok(images)
    }

    fn clean_text(&self, text: &str) -> String {
        // Unicodeè§„èŒƒåŒ–å’Œæ¸…ç†
        let normalized: String = text.nfc().collect();
        let decoded = decode_html_entities(&normalized).unwrap_or(normalized);
        
        // æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        let cleaned = decoded
            .lines()
            .map(|line| line.trim())
            .filter(|line| !line.is_empty())
            .collect::<Vec<_>>()
            .join(" ");

        cleaned.trim().to_string()
    }

    fn resolve_url(&self, href: &str, base_url: &str) -> Result<String> {
        if href.starts_with("http") {
            Ok(href.to_string())
        } else if href.starts_with("//") {
            Ok(format!("https:{}", href))
        } else if href.starts_with('/') {
            if let Ok(base) = url::Url::parse(base_url) {
                if let Some(host) = base.host_str() {
                    Ok(format!("{}://{}{}", base.scheme(), host, href))
                } else {
                    Err(anyhow!("æ— æ³•è§£æåŸºç¡€URL"))
                }
            } else {
                Err(anyhow!("æ— æ•ˆçš„åŸºç¡€URL"))
            }
        } else {
            // ç›¸å¯¹è·¯å¾„
            if let Ok(base) = url::Url::parse(base_url) {
                if let Ok(resolved) = base.join(href) {
                    Ok(resolved.to_string())
                } else {
                    Err(anyhow!("æ— æ³•è§£æç›¸å¯¹URL"))
                }
            } else {
                Err(anyhow!("æ— æ•ˆçš„åŸºç¡€URL"))
            }
        }
    }
}

/// å†…å®¹è´¨é‡è¯„ä¼°å™¨
pub struct ContentQualityAssessor {
    language_detector: Arc<LanguageDetector>,
}

impl ContentQualityAssessor {
    pub fn new() -> Self {
        let languages = vec![
            Language::English,
            Language::Chinese,
            Language::Japanese,
            Language::Korean,
            Language::German,
            Language::French,
            Language::Spanish,
            Language::Russian,
        ];
        
        let detector = LanguageDetectorBuilder::from_languages(&languages).build();
        
        Self {
            language_detector: Arc::new(detector),
        }
    }

    pub fn assess_quality(&self, content: &ContentExtractionResult) -> QualityMetrics {
        QualityMetrics {
            readability_score: self.calculate_readability(&content.main_content),
            coherence_score: self.calculate_coherence(&content.main_content),
            completeness_score: self.calculate_completeness(content),
            relevance_score: self.calculate_relevance(content),
            technical_content_score: self.calculate_technical_score(&content.main_content),
        }
    }

    fn calculate_readability(&self, content: &str) -> f32 {
        // å®Œæ•´çš„å¯è¯»æ€§è¯„ä¼°ç®—æ³•ï¼ˆåŸºäºFlesch Reading Easeï¼‰
        let words = content.split_whitespace().count() as f32;
        let sentences = content.split(&['.', '!', '?'][..])
            .filter(|s| !s.trim().is_empty())
            .count() as f32;
        
        // è®¡ç®—éŸ³èŠ‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼ŒåŸºäºå…ƒéŸ³è®¡æ•°ï¼‰
        let syllables = self.count_syllables(content);
        
        if sentences == 0.0 || words == 0.0 {
            return 0.0;
        }
        
        let avg_sentence_length = words / sentences;
        let avg_syllables_per_word = syllables / words;
        
        // Flesch Reading Easeå…¬å¼
        let flesch_score = 206.835 - (1.015 * avg_sentence_length) - (84.6 * avg_syllables_per_word);
        
        // å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        (flesch_score.max(0.0).min(100.0)) / 100.0
    }

    fn calculate_coherence(&self, content: &str) -> f32 {
        // å®Œæ•´çš„è¿è´¯æ€§è¯„ä¼°ç®—æ³•
        let sentences: Vec<&str> = content.split(&['.', '!', '?'][..])
            .filter(|s| !s.trim().is_empty())
            .collect();
        
        if sentences.len() < 2 {
            return 0.5; // å•å¥å†…å®¹ç»™äºˆä¸­ç­‰åˆ†æ•°
        }
        
        let mut coherence_score = 0.0;
        let mut total_comparisons = 0;
        
        // è®¡ç®—ç›¸é‚»å¥å­ä¹‹é—´çš„è¯æ±‡é‡å åº¦
        for i in 0..sentences.len() - 1 {
            let words1: std::collections::HashSet<String> = sentences[i]
                .split_whitespace()
                .map(|w| w.to_lowercase().trim_matches(|c: char| !c.is_alphabetic()).to_string())
                .filter(|w| w.len() > 2) // è¿‡æ»¤çŸ­è¯
                .collect();
            
            let words2: std::collections::HashSet<String> = sentences[i + 1]
                .split_whitespace()
                .map(|w| w.to_lowercase().trim_matches(|c: char| !c.is_alphabetic()).to_string())
                .filter(|w| w.len() > 2)
                .collect();
            
            if !words1.is_empty() && !words2.is_empty() {
                let intersection = words1.intersection(&words2).count() as f32;
                let union = words1.union(&words2).count() as f32;
                let jaccard_similarity = intersection / union;
                
                coherence_score += jaccard_similarity;
                total_comparisons += 1;
            }
        }
        
        // æ£€æŸ¥è¿æ¥è¯çš„ä½¿ç”¨
        let transition_words = [
            "however", "therefore", "furthermore", "moreover", "additionally",
            "consequently", "meanwhile", "similarly", "in contrast", "for example",
            "specifically", "in particular", "as a result", "on the other hand"
        ];
        
        let transition_count = transition_words.iter()
            .map(|&word| content.to_lowercase().matches(word).count())
            .sum::<usize>() as f32;
        
        let transition_bonus = (transition_count / sentences.len() as f32).min(0.3);
        
        if total_comparisons > 0 {
            (coherence_score / total_comparisons as f32) + transition_bonus
        } else {
            transition_bonus
        }
    }

    /// è®¡ç®—éŸ³èŠ‚æ•°ï¼ˆåŸºäºå…ƒéŸ³æ¨¡å¼ï¼‰
    fn count_syllables(&self, text: &str) -> f32 {
        let vowels = ['a', 'e', 'i', 'o', 'u', 'y'];
        let mut syllable_count = 0;
        
        for word in text.split_whitespace() {
            let clean_word = word.to_lowercase()
                .chars()
                .filter(|c| c.is_alphabetic())
                .collect::<String>();
            
            if clean_word.is_empty() {
                continue;
            }
            
            let mut word_syllables = 0;
            let mut prev_was_vowel = false;
            
            for ch in clean_word.chars() {
                let is_vowel = vowels.contains(&ch);
                if is_vowel && !prev_was_vowel {
                    word_syllables += 1;
                }
                prev_was_vowel = is_vowel;
            }
            
            // æ¯ä¸ªå•è¯è‡³å°‘æœ‰ä¸€ä¸ªéŸ³èŠ‚
            if word_syllables == 0 {
                word_syllables = 1;
            }
            
            // å¤„ç†silent e
            if clean_word.ends_with('e') && word_syllables > 1 {
                word_syllables -= 1;
            }
            
            syllable_count += word_syllables;
        }
        
        syllable_count as f32
    }

    fn calculate_completeness(&self, result: &ContentExtractionResult) -> f32 {
        let mut score = 0.0;
        
        if !result.title.is_empty() {
            score += 0.2;
        }
        
        if result.main_content.len() > 200 {
            score += 0.3;
        }
        
        if !result.links.is_empty() {
            score += 0.2;
        }
        
        if result.summary.is_some() {
            score += 0.15;
        }
        
        if result.detected_language.is_some() {
            score += 0.15;
        }
        
        score
    }

    fn calculate_relevance(&self, result: &ContentExtractionResult) -> f32 {
        // åŸºäºå†…å®¹ç»“æ„å’Œå…ƒç´ çš„ç›¸å…³æ€§è¯„ä¼°
        let mut score = 0.5; // åŸºç¡€åˆ†æ•°
        
        if !result.code_blocks.is_empty() {
            score += 0.2; // æŠ€æœ¯å†…å®¹é€šå¸¸æ›´ç›¸å…³
        }
        
        if !result.tables.is_empty() {
            score += 0.1; // ç»“æ„åŒ–æ•°æ®
        }
        
        if result.links.len() > 5 {
            score += 0.1; // ä¸°å¯Œçš„é“¾æ¥
        }
        
        score.min(1.0)
    }

    fn calculate_technical_score(&self, content: &str) -> f32 {
        let technical_keywords = [
            "api", "function", "class", "method", "algorithm", "implementation",
            "configuration", "parameter", "return", "example", "usage", "documentation",
            "tutorial", "guide", "reference", "specification",
        ];
        
        let content_lower = content.to_lowercase();
        let matches = technical_keywords.iter()
            .filter(|&&keyword| content_lower.contains(keyword))
            .count() as f32;
        
        (matches / technical_keywords.len() as f32).min(1.0)
    }
}

/// ç®¡é“æŒ‡æ ‡æ”¶é›†å™¨
#[derive(Debug, Default)]
pub struct PipelineMetrics {
    pub total_extractions: Arc<RwLock<u64>>,
    pub successful_extractions: Arc<RwLock<u64>>,
    pub failed_extractions: Arc<RwLock<u64>>,
    pub cache_hits: Arc<RwLock<u64>>,
    pub cache_misses: Arc<RwLock<u64>>,
    pub average_processing_time_ms: Arc<RwLock<f64>>,
    pub browser_renders: Arc<RwLock<u64>>,
}

impl PipelineMetrics {
    pub async fn record_extraction_success(&self, processing_time_ms: u64) {
        *self.total_extractions.write().await += 1;
        *self.successful_extractions.write().await += 1;
        
        let mut avg = self.average_processing_time_ms.write().await;
        *avg = (*avg + processing_time_ms as f64) / 2.0;
    }

    pub async fn record_extraction_failure(&self) {
        *self.total_extractions.write().await += 1;
        *self.failed_extractions.write().await += 1;
    }

    pub async fn record_cache_hit(&self) {
        *self.cache_hits.write().await += 1;
    }

    pub async fn record_cache_miss(&self) {
        *self.cache_misses.write().await += 1;
    }

    pub async fn record_browser_render(&self) {
        *self.browser_renders.write().await += 1;
    }
}

impl EnhancedContentPipeline {
    /// åˆ›å»ºæ–°çš„å¢å¼ºå†…å®¹ç®¡é“
    pub async fn new(config: PipelineConfig) -> Result<Self> {
        info!("ğŸš€ åˆå§‹åŒ–ä¼ä¸šçº§å†…å®¹å¤„ç†ç®¡é“");

        // åˆå§‹åŒ–è¯­è¨€æ£€æµ‹å™¨
        let languages = vec![
            Language::English, Language::Chinese, Language::Japanese,
            Language::Korean, Language::German, Language::French,
            Language::Spanish, Language::Russian, Language::Portuguese,
        ];
        let language_detector = Arc::new(
            LanguageDetectorBuilder::from_languages(&languages).build()
        );

        // åˆå§‹åŒ–ONNX Runtimeç¯å¢ƒ
        let ort_environment = Arc::new(
            Environment::builder()
                .with_name("grape-mcp-content-pipeline")
                .with_log_level(ort::LoggingLevel::Warning)
                .build()?
        );

        // åˆå§‹åŒ–æå–ç­–ç•¥
        let mut extraction_strategies: Vec<Arc<dyn ContentExtractionStrategy>> = Vec::new();
        
        if config.enabled_strategies.contains(&"readability".to_string()) {
            extraction_strategies.push(Arc::new(ReadabilityStrategy::new()));
        }

        // åˆå§‹åŒ–è´¨é‡è¯„ä¼°å™¨
        let quality_assessor = Arc::new(ContentQualityAssessor::new());

        // åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        let browser = if config.enable_browser_rendering {
            Some(Self::init_browser().await?)
        } else {
            None
        };

        Ok(Self {
            browser: Arc::new(RwLock::new(browser)),
            language_detector,
            ort_environment,
            extraction_strategies,
            quality_assessor,
            cache: Arc::new(RwLock::new(HashMap::new())),
            config,
            metrics: Arc::new(PipelineMetrics::default()),
        })
    }

    /// åˆå§‹åŒ–æµè§ˆå™¨
    async fn init_browser() -> Result<Browser> {
        info!("ğŸŒ åˆå§‹åŒ–Chromiumæµè§ˆå™¨å®ä¾‹");
        
        let config = BrowserConfig::builder()
            .with_head()
            .args(vec![
                "--no-sandbox",
                "--disable-dev-shm-usage", 
                "--disable-gpu",
                "--disable-features=VizDisplayCompositor",
            ])
            .build()
            .map_err(|e| anyhow!("æµè§ˆå™¨é…ç½®å¤±è´¥: {}", e))?;

        Browser::launch(config).await
            .map_err(|e| anyhow!("æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {}", e))
    }

    /// æå–ç½‘é¡µå†…å®¹
    pub async fn extract_content(&self, url: &str) -> Result<ContentExtractionResult> {
        let start_time = std::time::Instant::now();
        info!("ğŸ“„ å¼€å§‹æå–å†…å®¹: {}", url);

        // æ£€æŸ¥ç¼“å­˜
        let cache_key = self.generate_cache_key(url);
        if let Some(cached) = self.get_from_cache(&cache_key).await {
            self.metrics.record_cache_hit().await;
            info!("âœ… ç¼“å­˜å‘½ä¸­: {}", url);
            return Ok(cached.content);
        }
        self.metrics.record_cache_miss().await;

        // è·å–é¡µé¢å†…å®¹
        let html = if self.config.enable_browser_rendering {
            self.fetch_with_browser(url).await?
        } else {
            self.fetch_with_http(url).await?
        };

        // é€‰æ‹©æœ€ä½³æå–ç­–ç•¥
        let strategy = self.select_best_strategy(url);
        
        // æ‰§è¡Œæå–
        let mut result = strategy.extract(url, &html).await?;

        // è¯­è¨€æ£€æµ‹
        if let Some(language) = self.language_detector.detect_language_of(&result.main_content) {
            result.detected_language = Some(language);
        }

        // è´¨é‡è¯„ä¼°
        let quality_metrics = self.quality_assessor.assess_quality(&result);
        result.metadata.quality_metrics = quality_metrics;
        result.quality_score = self.calculate_overall_quality_score(&result);

        // æ›´æ–°å¤„ç†æ—¶é—´
        let processing_time = start_time.elapsed().as_millis() as u64;
        result.metadata.processing_time_ms = processing_time;

        // ç¼“å­˜ç»“æœ
        self.cache_result(&cache_key, &result).await;

        // è®°å½•æŒ‡æ ‡
        self.metrics.record_extraction_success(processing_time).await;

        info!("âœ… å†…å®¹æå–å®Œæˆï¼Œè´¨é‡åˆ†æ•°: {:.2}", result.quality_score);
        Ok(result)
    }

    /// ä½¿ç”¨æµè§ˆå™¨è·å–é¡µé¢å†…å®¹
    async fn fetch_with_browser(&self, url: &str) -> Result<String> {
        debug!("ğŸŒ ä½¿ç”¨æµè§ˆå™¨æ¸²æŸ“è·å–é¡µé¢: {}", url);
        
        let browser_guard = self.browser.read().await;
        let browser = browser_guard.as_ref()
            .ok_or_else(|| anyhow!("æµè§ˆå™¨æœªåˆå§‹åŒ–"))?;

        let page = browser.new_page("about:blank").await
            .map_err(|e| anyhow!("åˆ›å»ºé¡µé¢å¤±è´¥: {}", e))?;

        // è®¾ç½®è¶…æ—¶å’Œç”¨æˆ·ä»£ç†
        page.set_user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36").await
            .map_err(|e| anyhow!("è®¾ç½®ç”¨æˆ·ä»£ç†å¤±è´¥: {}", e))?;

        // å¯¼èˆªåˆ°ç›®æ ‡é¡µé¢
        page.goto(url).await
            .map_err(|e| anyhow!("é¡µé¢å¯¼èˆªå¤±è´¥: {}", e))?;

        // ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        page.wait_for_navigation().await
            .map_err(|e| anyhow!("ç­‰å¾…é¡µé¢åŠ è½½å¤±è´¥: {}", e))?;

        // è·å–é¡µé¢HTML
        let html = page.content().await
            .map_err(|e| anyhow!("è·å–é¡µé¢å†…å®¹å¤±è´¥: {}", e))?;

        self.metrics.record_browser_render().await;
        Ok(html)
    }

    /// ä½¿ç”¨HTTPå®¢æˆ·ç«¯è·å–é¡µé¢å†…å®¹
    async fn fetch_with_http(&self, url: &str) -> Result<String> {
        debug!("ğŸ“¡ ä½¿ç”¨HTTPå®¢æˆ·ç«¯è·å–é¡µé¢: {}", url);
        
        let client = reqwest::Client::new();
        let response = client
            .get(url)
            .header("User-Agent", "Mozilla/5.0 (compatible; Grape-MCP-DevTools/2.0)")
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(anyhow!("HTTPè¯·æ±‚å¤±è´¥: {}", response.status()));
        }

        let html = response.text().await?;
        Ok(html)
    }

    /// é€‰æ‹©æœ€ä½³æå–ç­–ç•¥
    fn select_best_strategy(&self, url: &str) -> Arc<dyn ContentExtractionStrategy> {
        for strategy in &self.extraction_strategies {
            if strategy.supports_url(url) {
                return strategy.clone();
            }
        }
        
        // é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªç­–ç•¥
        self.extraction_strategies[0].clone()
    }

    /// ç”Ÿæˆç¼“å­˜é”®
    fn generate_cache_key(&self, url: &str) -> String {
        use sha2::{Sha256, Digest};
        let mut hasher = Sha256::new();
        hasher.update(url.as_bytes());
        format!("{:x}", hasher.finalize())
    }

    /// ä»ç¼“å­˜è·å–å†…å®¹
    async fn get_from_cache(&self, key: &str) -> Option<CachedContent> {
        let cache = self.cache.read().await;
        if let Some(cached) = cache.get(key) {
            let age = Utc::now().signed_duration_since(cached.timestamp);
            if age.num_seconds() < self.config.cache_ttl_secs as i64 {
                return Some(cached.clone());
            }
        }
        None
    }

    /// ç¼“å­˜ç»“æœ
    async fn cache_result(&self, key: &str, result: &ContentExtractionResult) {
        let mut cache = self.cache.write().await;
        cache.insert(key.to_string(), CachedContent {
            content: result.clone(),
            timestamp: Utc::now(),
            access_count: 1,
        });
    }

    /// è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
    fn calculate_overall_quality_score(&self, result: &ContentExtractionResult) -> f32 {
        let metrics = &result.metadata.quality_metrics;
        
        // åŠ æƒå¹³å‡
        let weights = [0.3, 0.2, 0.2, 0.15, 0.15]; // å¯è¯»æ€§ã€è¿è´¯æ€§ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æŠ€æœ¯æ€§
        let scores = [
            metrics.readability_score,
            metrics.coherence_score,
            metrics.completeness_score,
            metrics.relevance_score,
            metrics.technical_content_score,
        ];
        
        weights.iter().zip(scores.iter())
            .map(|(w, s)| w * s)
            .sum()
    }

    /// è·å–ç®¡é“ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_statistics(&self) -> PipelineStatistics {
        PipelineStatistics {
            total_extractions: *self.metrics.total_extractions.read().await,
            successful_extractions: *self.metrics.successful_extractions.read().await,
            failed_extractions: *self.metrics.failed_extractions.read().await,
            cache_hits: *self.metrics.cache_hits.read().await,
            cache_misses: *self.metrics.cache_misses.read().await,
            average_processing_time_ms: *self.metrics.average_processing_time_ms.read().await,
            browser_renders: *self.metrics.browser_renders.read().await,
            cache_size: self.cache.read().await.len(),
            enabled_strategies: self.config.enabled_strategies.clone(),
        }
    }
}

/// ç®¡é“ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Serialize, Deserialize)]
pub struct PipelineStatistics {
    pub total_extractions: u64,
    pub successful_extractions: u64,
    pub failed_extractions: u64,
    pub cache_hits: u64,
    pub cache_misses: u64,
    pub average_processing_time_ms: f64,
    pub browser_renders: u64,
    pub cache_size: usize,
    pub enabled_strategies: Vec<String>,
} 
} 
