use anyhow::Result;
use serde_json::{json, Value};
use std::sync::Arc;

use crate::tools::base::MCPTool;
use crate::tools::docs::doc_traits::{
    DocumentFragment, DocumentStore, DocumentIndex, DocumentCache, DocumentVectorizer,
    DocumentVector, DocumentVectorMetadata, DocumentType, SearchFilter, SearchResult,
    DocElementKind, DocSourceType, DocMetadata, Visibility
};

// æ¨¡æ‹Ÿçš„ GoDocSearchTool å’Œ GoDocGeneratorï¼ˆç”¨äºæµ‹è¯•ï¼‰
pub struct GoDocSearchTool {
    vector_store: Arc<dyn DocumentIndex>,
    cache: Arc<dyn DocumentCache>,
    vectorizer: Arc<dyn DocumentVectorizer>,
}

impl GoDocSearchTool {
    pub fn new(
        vector_store: Arc<dyn DocumentIndex>,
        cache: Arc<dyn DocumentCache>,
        _doc_generator: Arc<GoDocGenerator>,
        vectorizer: Arc<dyn DocumentVectorizer>,
    ) -> Self {
        Self {
            vector_store,
            cache,
            vectorizer,
        }
    }

    pub async fn search_documentation(
        &self,
        package_name: &str,
        _version: Option<&str>,
        query: &str,
    ) -> Result<Value> {
        // æ¨¡æ‹Ÿæœç´¢é€»è¾‘
        let filter = SearchFilter {
            doc_types: None,
            languages: Some(vec!["go".to_string()]),
            limit: Some(10),
            similarity_threshold: Some(0.5),
        };

        let results = self.vector_store.search(query, &filter).await?;
        
        if !results.is_empty() {
            Ok(json!({
                "status": "success",
                "source": "vector_store",
                "package": package_name,
                "results": results.len()
            }))
        } else {
            Ok(json!({
                "status": "failure",
                "package": package_name,
                "message": "LLMè°ƒç”¨å·¥å…·å¤±è´¥"
            }))
        }
    }
}

pub struct GoDocGenerator;

impl GoDocGenerator {
    pub fn new() -> Self {
        Self
    }
}

/// Go æ–‡æ¡£æœç´¢ MCP å·¥å…· - ä½œä¸º LLM å¯è°ƒç”¨çš„å·¥å…·
pub struct GoDocSearchMCPTool {
    search_tool: Arc<GoDocSearchTool>,
}

impl GoDocSearchMCPTool {
    pub fn new(search_tool: Arc<GoDocSearchTool>) -> Self {
        Self { search_tool }
    }
}

#[async_trait::async_trait]
impl MCPTool for GoDocSearchMCPTool {
    fn name(&self) -> &str {
        "search_go_documentation"
    }

    fn description(&self) -> &str {
        "æœç´¢ Go è¯­è¨€åº“æ–‡æ¡£ã€‚é¦–å…ˆä»å‘é‡åº“æœç´¢ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™ç”Ÿæˆæœ¬åœ°æ–‡æ¡£å¹¶å‘é‡åŒ–å­˜å‚¨ï¼Œç„¶åå†æ¬¡æœç´¢ã€‚"
    }

    fn parameters_schema(&self) -> &crate::tools::base::Schema {
        use std::sync::OnceLock;
        use std::collections::HashMap;
        use crate::tools::base::{Schema, SchemaObject, SchemaString};

        static SCHEMA: OnceLock<Schema> = OnceLock::new();
        
        SCHEMA.get_or_init(|| {
            Schema::Object(SchemaObject {
                required: vec!["package_name".to_string(), "query".to_string()],
                properties: {
                    let mut map = HashMap::new();
                    map.insert("package_name".to_string(), Schema::String(SchemaString {
                        description: Some("Go åŒ…åï¼Œå¦‚ fmtã€github.com/gin-gonic/gin".to_string()),
                        enum_values: None,
                    }));
                    map.insert("version".to_string(), Schema::String(SchemaString {
                        description: Some("åŒ…ç‰ˆæœ¬å·ï¼Œå¦‚ v1.9.1ï¼Œç•™ç©ºè¡¨ç¤ºæœ€æ–°ç‰ˆæœ¬".to_string()),
                        enum_values: None,
                    }));
                    map.insert("query".to_string(), Schema::String(SchemaString {
                        description: Some("æœç´¢æŸ¥è¯¢ï¼Œå¦‚ 'Context usage'ã€'HTTP handler'".to_string()),
                        enum_values: None,
                    }));
                    map
                },
                ..Default::default()
            })
        })
    }

    async fn execute(&self, params: Value) -> Result<Value> {
        // éªŒè¯å‚æ•°
        self.validate_params(&params)?;

        // æå–å‚æ•°
        let package_name = params["package_name"]
            .as_str()
            .ok_or_else(|| anyhow::anyhow!("package_name å‚æ•°æ— æ•ˆ"))?;
            
        let version = params["version"].as_str();
        
        let query = params["query"]
            .as_str()
            .ok_or_else(|| anyhow::anyhow!("query å‚æ•°æ— æ•ˆ"))?;

        // è°ƒç”¨æ ¸å¿ƒæœç´¢é€»è¾‘
        self.search_tool
            .search_documentation(package_name, version, query)
            .await
    }
}

/// ç®€å•çš„å†…å­˜æ–‡æ¡£å­˜å‚¨å®ç°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
pub struct InMemoryDocumentStore {
    documents: Arc<tokio::sync::RwLock<std::collections::HashMap<String, DocumentFragment>>>,
}

impl InMemoryDocumentStore {
    pub fn new() -> Self {
        Self {
            documents: Arc::new(tokio::sync::RwLock::new(std::collections::HashMap::new())),
        }
    }
}

#[async_trait::async_trait]
impl DocumentStore for InMemoryDocumentStore {
    async fn store(&self, fragment: &DocumentFragment) -> Result<()> {
        let mut docs = self.documents.write().await;
        docs.insert(fragment.id.clone(), fragment.clone());
        Ok(())
    }

    async fn get(&self, id: &str) -> Result<Option<DocumentFragment>> {
        let docs = self.documents.read().await;
        Ok(docs.get(id).cloned())
    }

    async fn delete(&self, id: &str) -> Result<()> {
        let mut docs = self.documents.write().await;
        docs.remove(id);
        Ok(())
    }

    async fn list_all(&self) -> Result<Vec<DocumentFragment>> {
        let docs = self.documents.read().await;
        Ok(docs.values().cloned().collect())
    }
}

/// ç®€å•çš„å†…å­˜å‘é‡ç´¢å¼•å®ç°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
pub struct InMemoryVectorIndex {
    fragments: Arc<tokio::sync::RwLock<Vec<DocumentFragment>>>,
}

impl InMemoryVectorIndex {
    pub fn new() -> Self {
        Self {
            fragments: Arc::new(tokio::sync::RwLock::new(Vec::new())),
        }
    }
}

#[async_trait::async_trait]
impl DocumentIndex for InMemoryVectorIndex {
    async fn index(&self, fragment: &DocumentFragment) -> Result<()> {
        let mut fragments = self.fragments.write().await;
        fragments.push(fragment.clone());
        Ok(())
    }

    async fn search(&self, query: &str, filter: &SearchFilter) -> Result<Vec<SearchResult>> {
        let fragments = self.fragments.read().await;
        let mut results = Vec::new();

        for fragment in fragments.iter() {
            // ç®€å•çš„æ–‡æœ¬åŒ¹é…æœç´¢
            let content_lower = fragment.description.to_lowercase();
            let title_lower = fragment.title.to_lowercase();
            let query_lower = query.to_lowercase();

            let score = if title_lower.contains(&query_lower) {
                0.9
            } else if content_lower.contains(&query_lower) {
                0.7
            } else {
                0.0
            };

            if score >= filter.similarity_threshold.unwrap_or(0.5) {
                results.push(SearchResult {
                    fragment: fragment.clone(),
                    score,
                });
            }
        }

        // æŒ‰ç›¸å…³åº¦æ’åº
        results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());

        // é™åˆ¶ç»“æœæ•°é‡
        if let Some(limit) = filter.limit {
            results.truncate(limit);
        }

        Ok(results)
    }

    async fn delete(&self, id: &str) -> Result<()> {
        let mut fragments = self.fragments.write().await;
        fragments.retain(|f| f.id != id);
        Ok(())
    }

    async fn clear(&self) -> Result<()> {
        let mut fragments = self.fragments.write().await;
        fragments.clear();
        Ok(())
    }
}

/// ç®€å•çš„å†…å­˜ç¼“å­˜å®ç°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
pub struct InMemoryCache {
    cache: Arc<tokio::sync::RwLock<std::collections::HashMap<String, DocumentFragment>>>,
}

impl InMemoryCache {
    pub fn new() -> Self {
        Self {
            cache: Arc::new(tokio::sync::RwLock::new(std::collections::HashMap::new())),
        }
    }
}

#[async_trait::async_trait]
impl DocumentCache for InMemoryCache {
    async fn get(&self, key: &str) -> Result<Option<DocumentFragment>> {
        let cache = self.cache.read().await;
        Ok(cache.get(key).cloned())
    }

    async fn set(&self, key: &str, fragment: &DocumentFragment) -> Result<()> {
        let mut cache = self.cache.write().await;
        cache.insert(key.to_string(), fragment.clone());
        Ok(())
    }

    async fn delete(&self, key: &str) -> Result<()> {
        let mut cache = self.cache.write().await;
        cache.remove(key);
        Ok(())
    }

    async fn clear(&self) -> Result<()> {
        let mut cache = self.cache.write().await;
        cache.clear();
        Ok(())
    }
}

/// ç®€å•çš„å‘é‡åŒ–å™¨å®ç°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
pub struct SimpleVectorizer;

#[async_trait::async_trait]
impl DocumentVectorizer for SimpleVectorizer {
    async fn vectorize(&self, fragment: &DocumentFragment) -> Result<DocumentVector> {
        // ç®€å•çš„å‘é‡åŒ–ï¼šåŸºäºå…³é”®è¯è®¡æ•°
        let keywords = extract_keywords(&fragment.description);
        let mut vector_data = vec![0.0; 3]; // ç®€åŒ–ä¸º3ç»´å‘é‡
        
        // åŸºäºå…³é”®è¯è®¾ç½®å‘é‡å€¼
        for keyword in &keywords {
            match keyword.as_str() {
                "func" | "function" => vector_data[0] += 1.0,
                "type" | "struct" | "interface" => vector_data[1] += 1.0,
                "package" | "import" => vector_data[2] += 1.0,
                _ => {}
            }
        }

        // å½’ä¸€åŒ–
        let magnitude: f32 = vector_data.iter().map(|x| x * x).sum::<f32>().sqrt();
        if magnitude > 0.0 {
            for val in &mut vector_data {
                *val /= magnitude;
            }
        }

        Ok(DocumentVector {
            data: vector_data,
            dimension: 3,
            metadata: DocumentVectorMetadata {
                doc_id: fragment.id.clone(),
                doc_type: DocumentType::Api,
                language: fragment.metadata.language.clone(),
                keywords,
            },
        })
    }

    async fn devectorize(&self, vector: &DocumentVector) -> Result<DocumentFragment> {
        // ç®€å•çš„åå‘é‡åŒ–ï¼ˆå®é™…åº”ç”¨ä¸­ä¸å¤ªå¯èƒ½å®Œç¾è¿˜åŸï¼‰
        Ok(DocumentFragment {
            id: vector.metadata.doc_id.clone(),
            title: "Devectorized Document".to_string(),
            kind: DocElementKind::Function,
            full_name: None,
            description: format!("Vector data: {:?}", vector.data),
            source_type: DocSourceType::ApiDoc,
            code_context: None,
            examples: vec![],
            api_info: None,
            references: vec![],
            metadata: DocMetadata {
                package_name: "unknown".to_string(),
                version: None,
                language: vector.metadata.language.clone(),
                source_url: None,
                deprecated: false,
                since_version: None,
                visibility: Visibility::Public,
            },
            changelog_info: None,
        })
    }

    fn calculate_similarity(&self, vec1: &DocumentVector, vec2: &DocumentVector) -> f32 {
        // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        let dot_product: f32 = vec1.data.iter().zip(&vec2.data).map(|(a, b)| a * b).sum();
        let magnitude1: f32 = vec1.data.iter().map(|x| x * x).sum::<f32>().sqrt();
        let magnitude2: f32 = vec2.data.iter().map(|x| x * x).sum::<f32>().sqrt();
        
        if magnitude1 > 0.0 && magnitude2 > 0.0 {
            dot_product / (magnitude1 * magnitude2)
        } else {
            0.0
        }
    }
}

/// æå–å…³é”®è¯
fn extract_keywords(content: &str) -> Vec<String> {
    content
        .split_whitespace()
        .map(|word| word.to_lowercase().trim_matches(|c: char| !c.is_alphanumeric()).to_string())
        .filter(|word| !word.is_empty() && word.len() > 2)
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    async fn setup_test_environment() -> GoDocSearchMCPTool {
        let vector_store = Arc::new(InMemoryVectorIndex::new());
        let cache = Arc::new(InMemoryCache::new());
        let doc_generator = Arc::new(GoDocGenerator::new());
        let vectorizer = Arc::new(SimpleVectorizer);

        let search_tool = Arc::new(GoDocSearchTool::new(
            vector_store,
            cache,
            doc_generator,
            vectorizer,
        ));

        GoDocSearchMCPTool::new(search_tool)
    }

    /// æµ‹è¯•å®Œæ•´çš„Goæ–‡æ¡£æœç´¢å·¥ä½œæµç¨‹
    /// è¿™ä¸ªæµ‹è¯•éªŒè¯äº†LLMé€šè¿‡MCPå·¥å…·æœç´¢Goè¯­è¨€åº“æ–‡æ¡£çš„å®Œæ•´æµç¨‹ï¼š
    /// 1. é¦–å…ˆä»å‘é‡åº“æœç´¢
    /// 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç”Ÿæˆæœ¬åœ°æ–‡æ¡£
    /// 3. å°†æ–‡æ¡£å‘é‡åŒ–å¹¶å­˜å‚¨
    /// 4. å†æ¬¡æœç´¢
    /// 5. å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¿”å›å¤±è´¥
    #[tokio::test]
    async fn test_complete_go_documentation_workflow() {
        println!("ğŸš€ å¼€å§‹å®Œæ•´çš„Goæ–‡æ¡£æœç´¢å·¥ä½œæµç¨‹æµ‹è¯•...");

        let mcp_tool = setup_test_environment().await;

        // åœºæ™¯1: æœç´¢æ ‡å‡†åº“åŒ… fmt
        println!("\nğŸ“š åœºæ™¯1: æœç´¢Goæ ‡å‡†åº“fmtåŒ…çš„Printfå‡½æ•°...");
        
        let params = json!({
            "package_name": "fmt",
            "query": "Printf function"
        });

        let result = mcp_tool.execute(params).await.unwrap();
        let result_obj = result.as_object().unwrap();

        println!("ğŸ“Š æœç´¢ç»“æœçŠ¶æ€: {}", result_obj["status"]);
        println!("ğŸ“¦ åŒ…å: {}", result_obj["package"]);

        // éªŒè¯ç»“æœç»“æ„
        assert!(result_obj.contains_key("status"));
        assert!(result_obj.contains_key("package"));
        assert_eq!(result_obj["package"], "fmt");

        // æ ¹æ®çŠ¶æ€éªŒè¯ç»“æœ
        match result_obj["status"].as_str().unwrap() {
            "success" => {
                println!("âœ… æˆåŠŸæ‰¾åˆ°æ–‡æ¡£");
                if result_obj["source"] == "vector_store" {
                    println!("ğŸ“š æ¥æºï¼šå‘é‡åº“");
                } else if result_obj["source"] == "generated_docs" {
                    println!("ğŸ“š æ¥æºï¼šç”Ÿæˆçš„æœ¬åœ°æ–‡æ¡£");
                    if let Some(fragments) = result_obj.get("generated_fragments") {
                        println!("ğŸ“„ ç”Ÿæˆäº† {} ä¸ªæ–‡æ¡£ç‰‡æ®µ", fragments);
                    }
                }
                assert!(result_obj.contains_key("results"));
            }
            "partial_success" => {
                println!("âš ï¸  ç”Ÿæˆäº†æ–‡æ¡£ä½†æœªæ‰¾åˆ°ç›¸å…³å†…å®¹");
                assert!(result_obj.contains_key("generated_fragments"));
            }
            "failure" => {
                println!("âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {}", result_obj.get("error").unwrap_or(&json!("æœªçŸ¥é”™è¯¯")));
                assert!(result_obj.contains_key("message"));
                assert!(result_obj["message"].as_str().unwrap().contains("LLMè°ƒç”¨å·¥å…·å¤±è´¥"));
            }
            unknown_status => {
                println!("âš ï¸  æœªçŸ¥çš„çŠ¶æ€: {}", unknown_status);
                // è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµ‹è¯•
            }
        }

        // åœºæ™¯2: å†æ¬¡æœç´¢ç›¸åŒçš„åŒ…ï¼ˆæµ‹è¯•ç¼“å­˜æ•ˆæœï¼‰
        println!("\nğŸ”„ åœºæ™¯2: å†æ¬¡æœç´¢fmtåŒ…çš„Sprintfå‡½æ•°ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰...");
        
        let params2 = json!({
            "package_name": "fmt",
            "query": "Sprintf function"
        });

        let result2 = mcp_tool.execute(params2).await.unwrap();
        let result2_obj = result2.as_object().unwrap();

        println!("ğŸ“Š ç¬¬äºŒæ¬¡æœç´¢çŠ¶æ€: {}", result2_obj["status"]);
        
        // ç¬¬äºŒæ¬¡æœç´¢åº”è¯¥æ›´å¿«ï¼Œå› ä¸ºæ–‡æ¡£å·²ç»åœ¨å‘é‡åº“ä¸­
        if result2_obj["status"] == "success" && result2_obj["source"] == "vector_store" {
            println!("âœ… æˆåŠŸä»å‘é‡åº“è·å–ç¼“å­˜çš„æ–‡æ¡£");
        }

        // åœºæ™¯3: æœç´¢ä¸å­˜åœ¨çš„åŒ…
        println!("\nâŒ åœºæ™¯3: æœç´¢ä¸å­˜åœ¨çš„åŒ…...");
        
        let params3 = json!({
            "package_name": "github.com/nonexistent/invalid-package-12345",
            "version": "v999.999.999",
            "query": "some function"
        });

        let result3 = mcp_tool.execute(params3).await.unwrap();
        let result3_obj = result3.as_object().unwrap();

        println!("ğŸ“Š ä¸å­˜åœ¨åŒ…çš„æœç´¢çŠ¶æ€: {}", result3_obj["status"]);
        
        // åº”è¯¥è¿”å›å¤±è´¥çŠ¶æ€
        assert_eq!(result3_obj["status"], "failure");
        assert!(result3_obj["message"].as_str().unwrap().contains("LLMè°ƒç”¨å·¥å…·å¤±è´¥"));
        println!("âœ… æ­£ç¡®å¤„ç†äº†ä¸å­˜åœ¨çš„åŒ…");

        // åœºæ™¯4: æµ‹è¯•å‚æ•°éªŒè¯
        println!("\nğŸ” åœºæ™¯4: æµ‹è¯•å‚æ•°éªŒè¯...");
        
        let invalid_params = json!({
            "package_name": "fmt"
            // ç¼ºå°‘å¿…éœ€çš„ query å‚æ•°
        });

        let result4 = mcp_tool.execute(invalid_params).await;
        assert!(result4.is_err());
        println!("âœ… æ­£ç¡®æ£€æµ‹åˆ°ç¼ºå°‘å¿…éœ€å‚æ•°");

        println!("\nğŸ‰ å®Œæ•´çš„Goæ–‡æ¡£æœç´¢å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆï¼");
    }

    /// æµ‹è¯•å·¥å…·å…ƒæ•°æ®
    #[tokio::test]
    async fn test_tool_metadata() {
        println!("ğŸ“‹ æµ‹è¯•å·¥å…·å…ƒæ•°æ®...");

        let mcp_tool = setup_test_environment().await;

        // éªŒè¯å·¥å…·åç§°
        assert_eq!(mcp_tool.name(), "search_go_documentation");
        println!("âœ… å·¥å…·åç§°æ­£ç¡®: {}", mcp_tool.name());

        // éªŒè¯å·¥å…·æè¿°
        let description = mcp_tool.description();
        assert!(description.contains("æœç´¢ Go è¯­è¨€åº“æ–‡æ¡£"));
        assert!(description.contains("å‘é‡åº“"));
        println!("âœ… å·¥å…·æè¿°æ­£ç¡®");

        // éªŒè¯å‚æ•°æ¨¡å¼
        let schema = mcp_tool.parameters_schema();
        if let crate::tools::base::Schema::Object(obj) = schema {
            assert!(obj.required.contains(&"package_name".to_string()));
            assert!(obj.required.contains(&"query".to_string()));
            assert!(obj.properties.contains_key("package_name"));
            assert!(obj.properties.contains_key("query"));
            assert!(obj.properties.contains_key("version"));
            println!("âœ… å‚æ•°æ¨¡å¼æ­£ç¡®");
        } else {
            println!("âš ï¸  å‚æ•°æ¨¡å¼ä¸æ˜¯æœŸæœ›çš„SchemaObjectç±»å‹");
            // è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµ‹è¯•
        }

        println!("ğŸ‰ å·¥å…·å…ƒæ•°æ®æµ‹è¯•å®Œæˆï¼");
    }

    /// æµ‹è¯•å‘é‡å­˜å‚¨æ“ä½œ
    #[tokio::test]
    async fn test_vector_store_operations() {
        println!("ğŸ“Š æµ‹è¯•å‘é‡å­˜å‚¨æ“ä½œ...");

        let vector_store = InMemoryVectorIndex::new();
        
        let test_fragment = DocumentFragment {
            id: "test_doc".to_string(),
            title: "Test Document".to_string(),
            kind: DocElementKind::Function,
            full_name: Some("test.Printf".to_string()),
            description: "This is a test document with Go programming content func Printf".to_string(),
            source_type: DocSourceType::ApiDoc,
            code_context: None,
            examples: vec![],
            api_info: None,
            references: vec![],
            metadata: DocMetadata {
                package_name: "test".to_string(),
                version: None,
                language: "go".to_string(),
                source_url: None,
                deprecated: false,
                since_version: None,
                visibility: Visibility::Public,
            },
            changelog_info: None,
        };

        // æµ‹è¯•ç´¢å¼•
        vector_store.index(&test_fragment).await.unwrap();
        println!("âœ… æˆåŠŸç´¢å¼•æ–‡æ¡£");

        // æµ‹è¯•æœç´¢
        let filter = SearchFilter {
            doc_types: None,
            languages: Some(vec!["go".to_string()]),
            limit: Some(10),
            similarity_threshold: Some(0.5),
        };

        let results = vector_store.search("Printf", &filter).await.unwrap();
        assert!(!results.is_empty());
        assert_eq!(results[0].fragment.id, "test_doc");
        println!("âœ… æˆåŠŸæœç´¢åˆ°æ–‡æ¡£");

        // æµ‹è¯•åˆ é™¤
        vector_store.delete("test_doc").await.unwrap();
        let results_after_delete = vector_store.search("Printf", &filter).await.unwrap();
        assert!(results_after_delete.is_empty());
        println!("âœ… æˆåŠŸåˆ é™¤æ–‡æ¡£");

        println!("ğŸ‰ å‘é‡å­˜å‚¨æ“ä½œæµ‹è¯•å®Œæˆï¼");
    }

    /// æµ‹è¯•ç¼“å­˜æ“ä½œ
    #[tokio::test]
    async fn test_cache_operations() {
        println!("ğŸ’¾ æµ‹è¯•ç¼“å­˜æ“ä½œ...");

        let cache = InMemoryCache::new();
        
        let test_fragment = DocumentFragment {
            id: "cached_doc".to_string(),
            title: "Cached Document".to_string(),
            kind: DocElementKind::Function,
            full_name: Some("cache.Get".to_string()),
            description: "This document is cached".to_string(),
            source_type: DocSourceType::ApiDoc,
            code_context: None,
            examples: vec![],
            api_info: None,
            references: vec![],
            metadata: DocMetadata {
                package_name: "cache".to_string(),
                version: None,
                language: "go".to_string(),
                source_url: None,
                deprecated: false,
                since_version: None,
                visibility: Visibility::Public,
            },
            changelog_info: None,
        };

        // æµ‹è¯•è®¾ç½®ç¼“å­˜
        cache.set("test_key", &test_fragment).await.unwrap();
        println!("âœ… æˆåŠŸè®¾ç½®ç¼“å­˜");

        // æµ‹è¯•è·å–ç¼“å­˜
        let retrieved = cache.get("test_key").await.unwrap();
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().id, "cached_doc");
        println!("âœ… æˆåŠŸè·å–ç¼“å­˜");

        // æµ‹è¯•åˆ é™¤ç¼“å­˜
        cache.delete("test_key").await.unwrap();
        let retrieved_after_delete = cache.get("test_key").await.unwrap();
        assert!(retrieved_after_delete.is_none());
        println!("âœ… æˆåŠŸåˆ é™¤ç¼“å­˜");

        println!("ğŸ‰ ç¼“å­˜æ“ä½œæµ‹è¯•å®Œæˆï¼");
    }

    /// æµ‹è¯•å‘é‡åŒ–å™¨æ“ä½œ
    #[tokio::test]
    async fn test_vectorizer_operations() {
        println!("ğŸ”¢ æµ‹è¯•å‘é‡åŒ–å™¨æ“ä½œ...");

        let vectorizer = SimpleVectorizer;
        
        let test_fragment = DocumentFragment {
            id: "vector_test".to_string(),
            title: "Vector Test".to_string(),
            kind: DocElementKind::Function,
            full_name: Some("fmt.Printf".to_string()),
            description: "func Printf(format string) This is content for vectorization testing".to_string(),
            source_type: DocSourceType::ApiDoc,
            code_context: None,
            examples: vec![],
            api_info: None,
            references: vec![],
            metadata: DocMetadata {
                package_name: "fmt".to_string(),
                version: None,
                language: "go".to_string(),
                source_url: None,
                deprecated: false,
                since_version: None,
                visibility: Visibility::Public,
            },
            changelog_info: None,
        };

        // æµ‹è¯•å‘é‡åŒ–
        let vector = vectorizer.vectorize(&test_fragment).await.unwrap();
        assert_eq!(vector.dimension, 3);
        assert_eq!(vector.data.len(), 3);
        assert_eq!(vector.metadata.doc_id, "vector_test");
        println!("âœ… æˆåŠŸå‘é‡åŒ–æ–‡æ¡£");

        // æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        let vector2 = vectorizer.vectorize(&test_fragment).await.unwrap();
        let similarity = vectorizer.calculate_similarity(&vector, &vector2);
        assert!((similarity - 1.0).abs() < 0.001); // ç›¸åŒæ–‡æ¡£åº”è¯¥ç›¸ä¼¼åº¦ä¸º1
        println!("âœ… ç›¸ä¼¼åº¦è®¡ç®—æ­£ç¡®: {:.3}", similarity);

        println!("ğŸ‰ å‘é‡åŒ–å™¨æ“ä½œæµ‹è¯•å®Œæˆï¼");
    }
} 